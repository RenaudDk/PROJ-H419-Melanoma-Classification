{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eae82575",
   "metadata": {},
   "source": [
    "# Small Model v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a75b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "import PIL.Image\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "import pathlib\n",
    "import pandas as pd\n",
    "\n",
    "import pydicom # for DICOM images\n",
    "from skimage.transform import resize\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aee4e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1022b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed=31415):\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
    "set_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e7b5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory\n",
    "directory = '/Users/renau/Desktop/DATA/data_proj_melanoma'\n",
    "\n",
    "# Import the 2 csv s\n",
    "train_df = pd.read_csv(directory + '/train.csv')\n",
    "test_df = pd.read_csv(directory + '/test.csv')\n",
    "\n",
    "print('Train has {:,} rows and Test has {:,} rows.'.format(len(train_df), len(test_df)))\n",
    "\n",
    "# Change columns names\n",
    "new_names = ['dcm_name', 'ID', 'sex', 'age', 'anatomy', 'diagnosis', 'benign_malignant', 'target']\n",
    "train_df.columns = new_names\n",
    "test_df.columns = new_names[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e09f3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === DICOM ===\n",
    "# Create the paths\n",
    "path_train = directory + '/train/' + train_df['dcm_name'] + '.dcm'\n",
    "path_test = directory + '/test/' + test_df['dcm_name'] + '.dcm'\n",
    "\n",
    "# Append to the original dataframes\n",
    "train_df['path_dicom'] = path_train\n",
    "test_df['path_dicom'] = path_test\n",
    "\n",
    "# === JPEG ===\n",
    "# Create the paths\n",
    "path_train = directory + '/jpeg/train/' + train_df['dcm_name'] + '.jpg'\n",
    "path_test = directory + '/jpeg/test/' + test_df['dcm_name'] + '.jpg'\n",
    "\n",
    "# Append to the original dataframes\n",
    "train_df['path_jpeg'] = path_train\n",
    "test_df['path_jpeg'] = path_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30500adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_images(data, n = 5, rows=1, cols=5, title='Default'):\n",
    "    plt.figure(figsize=(16,4))\n",
    "\n",
    "    for k, path in enumerate(data['path_dicom'][:n]):\n",
    "        image = pydicom.read_file(path)\n",
    "        image = image.pixel_array\n",
    "        \n",
    "        image = resize(image, (200, 200), anti_aliasing=True)\n",
    "\n",
    "        plt.suptitle(title, fontsize = 16)\n",
    "        plt.subplot(rows, cols, k+1)\n",
    "        plt.imshow(image)\n",
    "        plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81b5b94",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "show_images(train_df[train_df['target'] == 0], n=5, rows=1, cols=5, title='Benign Sample')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1df79b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show Malignant Samples\n",
    "show_images(train_df[train_df['target'] == 1], n=5, rows=1, cols=5, title='Malignant Sample')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33cdf566",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a7cf29",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths = train_df['path_jpeg'].values\n",
    "labels = train_df['target'].values\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((file_paths, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7452be65",
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_ds = train_ds.take(3)\n",
    "for element in ex_ds :\n",
    "    print(element[0].numpy(),'and target: ',element[1].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724bf6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image(path, label):\n",
    "    image = tf.io.read_file(path)\n",
    "    image = tf.image.decode_image(image, channels=3, dtype = tf.uint8, expand_animations = False)\n",
    "    return image, label\n",
    "dstry = train_ds.map(read_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae09d9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_ds = dstry.take(3)\n",
    "for element in ex_ds :\n",
    "    print(element[0].numpy().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222d1391-24e9-436b-9c34-cd8474bcd4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cut = 24000\n",
    "ds_train = dstry.take(cut) \n",
    "ds_val = dstry.skip(cut)\n",
    "\n",
    "def adapt_data(image, label):\n",
    "    image = tf.image.resize(image, [128,128])\n",
    "    return image, label\n",
    "\n",
    "def convert_to_float(image, label):\n",
    "    image = tf.image.convert_image_dtype(image, dtype=tf.float32)\n",
    "    return image, label\n",
    "    \n",
    "ds_train= ds_train.map(adapt_data).map(convert_to_float).batch(64)\n",
    "ds_val= ds_val.map(adapt_data).map(convert_to_float).batch(64)\n",
    "\n",
    "ex_ds = ds_train.take(3)\n",
    "for element in ex_ds :\n",
    "    print(element[0].shape)\n",
    "    print(element[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16f2e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "ds_train = ds_train.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "ds_val = ds_val.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c41ebe5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "\n",
    "model = keras.Sequential([\n",
    "    # Block One\n",
    "    layers.Conv2D(filters=32, kernel_size=3, activation='relu', padding='same',\n",
    "                  input_shape=[128,128, 3]),\n",
    "    layers.MaxPool2D(),\n",
    "\n",
    "    # Block Two\n",
    "    layers.Conv2D(filters=64, kernel_size=3, activation='relu', padding='same'),\n",
    "    layers.MaxPool2D(),\n",
    "\n",
    "    # Block Three\n",
    "    layers.Conv2D(filters=128, kernel_size=3, activation='relu', padding='same'),\n",
    "    layers.Conv2D(filters=128, kernel_size=3, activation='relu', padding='same'),\n",
    "    layers.MaxPool2D(),\n",
    "\n",
    "    # Head\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(6, activation='relu'),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.Dense(1, activation='sigmoid'),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f942f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(epsilon=0.01),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['binary_accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c25c91",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    ds_train,\n",
    "    validation_data=ds_val,\n",
    "    epochs=100,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62fe4e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "history_frame = pd.DataFrame(history.history)\n",
    "history_frame.loc[:, ['loss', 'val_loss']].plot()\n",
    "history_frame.loc[:, ['binary_accuracy', 'val_binary_accuracy']].plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377b9d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(ds_val)\n",
    "predictions = tf.argmax(predictions, axis=-1)\n",
    "b =0\n",
    "m = 0\n",
    "for element in predictions :\n",
    "    if(element.numpy() != 0) :\n",
    "        m +=1\n",
    "    else :\n",
    "        b +=1\n",
    "print(\"Prédictions ;\\n - Malin(s): \", m, \"\\n - Bénins: \", b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a83465-5418-47b2-9047-88a6d57aea73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42229ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
