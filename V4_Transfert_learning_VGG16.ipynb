{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eae82575",
   "metadata": {},
   "source": [
    "# WIP Data augmentation \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2a75b1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "import PIL.Image\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "import pathlib\n",
    "import pandas as pd\n",
    "\n",
    "import pydicom # for DICOM images\n",
    "from skimage.transform import resize\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "%matplotlib inline\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1022b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed=31415):\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
    "set_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0e7b5f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train has 33,126 rows and Test has 10,982 rows.\n"
     ]
    }
   ],
   "source": [
    "# Directory\n",
    "#directory = '/Users/renau/Desktop/DATA/data_proj_melanoma'\n",
    "directory = '/Users/renau/Desktop/PROJ-H419/data'\n",
    "\n",
    "# Import the 2 csv s\n",
    "train_df = pd.read_csv(directory + '/train.csv')\n",
    "test_df = pd.read_csv(directory + '/test.csv')\n",
    "\n",
    "print('Train has {:,} rows and Test has {:,} rows.'.format(len(train_df), len(test_df)))\n",
    "\n",
    "# Change columns names\n",
    "new_names = ['dcm_name', 'ID', 'sex', 'age', 'anatomy', 'diagnosis', 'benign_malignant', 'target']\n",
    "train_df.columns = new_names\n",
    "test_df.columns = new_names[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e09f3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === JPEG ===\n",
    "# Create the paths\n",
    "path_train = directory + '/jpeg/train/' + train_df['dcm_name'] + '.jpg'\n",
    "path_test = directory + '/jpeg/test/' + test_df['dcm_name'] + '.jpg'\n",
    "\n",
    "# Append to the original dataframes\n",
    "train_df['path_jpeg'] = path_train\n",
    "test_df['path_jpeg'] = path_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "670fb0a1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dcm_name</th>\n",
       "      <th>ID</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>anatomy</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>benign_malignant</th>\n",
       "      <th>target</th>\n",
       "      <th>path_jpeg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>ISIC_0149568</td>\n",
       "      <td>IP_0962375</td>\n",
       "      <td>female</td>\n",
       "      <td>55.0</td>\n",
       "      <td>upper extremity</td>\n",
       "      <td>melanoma</td>\n",
       "      <td>malignant</td>\n",
       "      <td>1</td>\n",
       "      <td>/Users/renau/Desktop/PROJ-H419/data/jpeg/train...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>ISIC_0188432</td>\n",
       "      <td>IP_0135517</td>\n",
       "      <td>female</td>\n",
       "      <td>50.0</td>\n",
       "      <td>upper extremity</td>\n",
       "      <td>melanoma</td>\n",
       "      <td>malignant</td>\n",
       "      <td>1</td>\n",
       "      <td>/Users/renau/Desktop/PROJ-H419/data/jpeg/train...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>ISIC_0207268</td>\n",
       "      <td>IP_7735373</td>\n",
       "      <td>male</td>\n",
       "      <td>55.0</td>\n",
       "      <td>torso</td>\n",
       "      <td>melanoma</td>\n",
       "      <td>malignant</td>\n",
       "      <td>1</td>\n",
       "      <td>/Users/renau/Desktop/PROJ-H419/data/jpeg/train...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>ISIC_0232101</td>\n",
       "      <td>IP_8349964</td>\n",
       "      <td>male</td>\n",
       "      <td>65.0</td>\n",
       "      <td>torso</td>\n",
       "      <td>melanoma</td>\n",
       "      <td>malignant</td>\n",
       "      <td>1</td>\n",
       "      <td>/Users/renau/Desktop/PROJ-H419/data/jpeg/train...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>ISIC_0247330</td>\n",
       "      <td>IP_3232631</td>\n",
       "      <td>female</td>\n",
       "      <td>65.0</td>\n",
       "      <td>lower extremity</td>\n",
       "      <td>melanoma</td>\n",
       "      <td>malignant</td>\n",
       "      <td>1</td>\n",
       "      <td>/Users/renau/Desktop/PROJ-H419/data/jpeg/train...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         dcm_name          ID     sex   age          anatomy diagnosis  \\\n",
       "91   ISIC_0149568  IP_0962375  female  55.0  upper extremity  melanoma   \n",
       "235  ISIC_0188432  IP_0135517  female  50.0  upper extremity  melanoma   \n",
       "314  ISIC_0207268  IP_7735373    male  55.0            torso  melanoma   \n",
       "399  ISIC_0232101  IP_8349964    male  65.0            torso  melanoma   \n",
       "459  ISIC_0247330  IP_3232631  female  65.0  lower extremity  melanoma   \n",
       "\n",
       "    benign_malignant  target  \\\n",
       "91         malignant       1   \n",
       "235        malignant       1   \n",
       "314        malignant       1   \n",
       "399        malignant       1   \n",
       "459        malignant       1   \n",
       "\n",
       "                                             path_jpeg  \n",
       "91   /Users/renau/Desktop/PROJ-H419/data/jpeg/train...  \n",
       "235  /Users/renau/Desktop/PROJ-H419/data/jpeg/train...  \n",
       "314  /Users/renau/Desktop/PROJ-H419/data/jpeg/train...  \n",
       "399  /Users/renau/Desktop/PROJ-H419/data/jpeg/train...  \n",
       "459  /Users/renau/Desktop/PROJ-H419/data/jpeg/train...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "malignant_df = train_df[train_df['target'] == 1]\n",
    "malignant_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d5691d32",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dcm_name</th>\n",
       "      <th>ID</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>anatomy</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>benign_malignant</th>\n",
       "      <th>target</th>\n",
       "      <th>path_jpeg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ISIC_2637011</td>\n",
       "      <td>IP_7279968</td>\n",
       "      <td>male</td>\n",
       "      <td>45.0</td>\n",
       "      <td>head/neck</td>\n",
       "      <td>unknown</td>\n",
       "      <td>benign</td>\n",
       "      <td>0</td>\n",
       "      <td>/Users/renau/Desktop/PROJ-H419/data/jpeg/train...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ISIC_0015719</td>\n",
       "      <td>IP_3075186</td>\n",
       "      <td>female</td>\n",
       "      <td>45.0</td>\n",
       "      <td>upper extremity</td>\n",
       "      <td>unknown</td>\n",
       "      <td>benign</td>\n",
       "      <td>0</td>\n",
       "      <td>/Users/renau/Desktop/PROJ-H419/data/jpeg/train...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ISIC_0052212</td>\n",
       "      <td>IP_2842074</td>\n",
       "      <td>female</td>\n",
       "      <td>50.0</td>\n",
       "      <td>lower extremity</td>\n",
       "      <td>nevus</td>\n",
       "      <td>benign</td>\n",
       "      <td>0</td>\n",
       "      <td>/Users/renau/Desktop/PROJ-H419/data/jpeg/train...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ISIC_0068279</td>\n",
       "      <td>IP_6890425</td>\n",
       "      <td>female</td>\n",
       "      <td>45.0</td>\n",
       "      <td>head/neck</td>\n",
       "      <td>unknown</td>\n",
       "      <td>benign</td>\n",
       "      <td>0</td>\n",
       "      <td>/Users/renau/Desktop/PROJ-H419/data/jpeg/train...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ISIC_0074268</td>\n",
       "      <td>IP_8723313</td>\n",
       "      <td>female</td>\n",
       "      <td>55.0</td>\n",
       "      <td>upper extremity</td>\n",
       "      <td>unknown</td>\n",
       "      <td>benign</td>\n",
       "      <td>0</td>\n",
       "      <td>/Users/renau/Desktop/PROJ-H419/data/jpeg/train...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       dcm_name          ID     sex   age          anatomy diagnosis  \\\n",
       "0  ISIC_2637011  IP_7279968    male  45.0        head/neck   unknown   \n",
       "1  ISIC_0015719  IP_3075186  female  45.0  upper extremity   unknown   \n",
       "2  ISIC_0052212  IP_2842074  female  50.0  lower extremity     nevus   \n",
       "3  ISIC_0068279  IP_6890425  female  45.0        head/neck   unknown   \n",
       "4  ISIC_0074268  IP_8723313  female  55.0  upper extremity   unknown   \n",
       "\n",
       "  benign_malignant  target                                          path_jpeg  \n",
       "0           benign       0  /Users/renau/Desktop/PROJ-H419/data/jpeg/train...  \n",
       "1           benign       0  /Users/renau/Desktop/PROJ-H419/data/jpeg/train...  \n",
       "2           benign       0  /Users/renau/Desktop/PROJ-H419/data/jpeg/train...  \n",
       "3           benign       0  /Users/renau/Desktop/PROJ-H419/data/jpeg/train...  \n",
       "4           benign       0  /Users/renau/Desktop/PROJ-H419/data/jpeg/train...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benin_df = train_df[train_df['target'] == 0]\n",
    "benin_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe8c4729",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "584"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mal_file = malignant_df['path_jpeg'].values\n",
    "mal_labels = malignant_df['target'].values\n",
    "mal_train_ds = tf.data.Dataset.from_tensor_slices((mal_file, mal_labels))\n",
    "len(list(mal_train_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae0eff34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32542"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ben_file = benin_df['path_jpeg'].values\n",
    "ben_labels = benin_df['target'].values\n",
    "ben_train_ds = tf.data.Dataset.from_tensor_slices((ben_file, ben_labels))\n",
    "len(list(ben_train_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d15a23f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32542"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ben_train_ds = ben_train_ds.shuffle(len(list(ben_train_ds)))\n",
    "len(list(ben_train_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "77b57288",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "233 935\n"
     ]
    }
   ],
   "source": [
    "def make_balanced_dataset(ds_class1, ds_class2):\n",
    "    half_size = min(len(list(ds_class1)),len(list(ds_class2)))\n",
    "    ds_1 = ds_class1.take(half_size)\n",
    "    ds_2 = ds_class2.take(half_size)\n",
    "    ds_full = ds_1.concatenate(ds_2)\n",
    "    ds_full = ds_full.shuffle(half_size*2, reshuffle_each_iteration=False)\n",
    "    return ds_full.skip((half_size*2)//5),ds_full.take((half_size*2)//5),\n",
    "#print(make_balanced_dataset(ben_train_ds,mal_train_ds))   \n",
    "ds_train, ds_val = make_balanced_dataset(ben_train_ds,mal_train_ds)\n",
    "size = len(list(ds_val))\n",
    "print(size, len(list(ds_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7452be65",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'/Users/renau/Desktop/PROJ-H419/data/jpeg/train/ISIC_6257422.jpg' and target:  0\n",
      "b'/Users/renau/Desktop/PROJ-H419/data/jpeg/train/ISIC_0599605.jpg' and target:  1\n",
      "b'/Users/renau/Desktop/PROJ-H419/data/jpeg/train/ISIC_0272026.jpg' and target:  0\n",
      "b'/Users/renau/Desktop/PROJ-H419/data/jpeg/train/ISIC_2937642.jpg' and target:  1\n"
     ]
    }
   ],
   "source": [
    "ex_ds = ds_train.take(4)\n",
    "for element in ex_ds :\n",
    "    print(element[0].numpy(),'and target: ',element[1].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "724bf6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image(path, label):\n",
    "    image = tf.io.read_file(path)\n",
    "    image = tf.image.decode_image(image, channels=3, dtype = tf.uint8, expand_animations = False)\n",
    "    return image, label\n",
    "\n",
    "ds_train = ds_train.map(read_image)\n",
    "ds_val = ds_val.map(read_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ae09d9ef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640, 3)\n",
      "(2448, 3264, 3)\n",
      "(4000, 6000, 3)\n"
     ]
    }
   ],
   "source": [
    "ex_ds = ds_train.take(3)\n",
    "for element in ex_ds :\n",
    "    print(element[0].numpy().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "222d1391-24e9-436b-9c34-cd8474bcd4e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 160, 160, 3)\n",
      "(16,)\n",
      "(16, 160, 160, 3)\n",
      "(16,)\n",
      "(16, 160, 160, 3)\n",
      "(16,)\n"
     ]
    }
   ],
   "source": [
    "def adapt_data(image, label):\n",
    "    image = tf.image.resize(image, [160,160])\n",
    "    return image, label\n",
    "\n",
    "def convert_to_float(image, label):\n",
    "    image = tf.image.convert_image_dtype(image, dtype=tf.float64)\n",
    "    return image, label\n",
    "    \n",
    "ds_train= ds_train.map(adapt_data).map(convert_to_float).batch(16)\n",
    "ds_val= ds_val.map(adapt_data).map(convert_to_float).batch(16)\n",
    "\n",
    "ex_ds = ds_train.take(3)\n",
    "for element in ex_ds :\n",
    "    print(element[0].shape)\n",
    "    print(element[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c16f2e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "ds_train = ds_train.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "ds_val = ds_val.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cd9828ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_input = tf.keras.applications.vgg16.preprocess_input\n",
    "IMG_SIZE = (160,160)\n",
    "IMG_SHAPE = IMG_SIZE + (3,)\n",
    "base_model = tf.keras.applications.vgg16.VGG16(\n",
    "    include_top=False,\n",
    "    weights='imagenet',\n",
    "    input_tensor=None,\n",
    "    input_shape=IMG_SHAPE,\n",
    "    pooling=None,\n",
    "    classes=2,\n",
    "    classifier_activation='softmax'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d0281b20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 5, 5, 512)\n"
     ]
    }
   ],
   "source": [
    "image_batch, label_batch = next(iter(ds_train))\n",
    "feature_batch = base_model(image_batch)\n",
    "print(feature_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3c94f445",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 160, 160, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 160, 160, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 160, 160, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 80, 80, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 80, 80, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 80, 80, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 40, 40, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 40, 40, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 40, 40, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 40, 40, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 20, 20, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 20, 20, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 20, 20, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 20, 20, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 10, 10, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 10, 10, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 10, 10, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 10, 10, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 5, 5, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 0\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model.trainable = False\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "15fbe6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    preprocessing.RandomContrast(factor=0.1),\n",
    "    preprocessing.RandomFlip(mode='horizontal'), \n",
    "    preprocessing.RandomFlip(mode='vertical'), \n",
    "    preprocessing.RandomRotation(factor=0.20),  \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c64c014d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 512)\n"
     ]
    }
   ],
   "source": [
    "global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
    "feature_batch_average = global_average_layer(feature_batch)\n",
    "print(feature_batch_average.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a4c9f42c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 1)\n"
     ]
    }
   ],
   "source": [
    "prediction_layer = tf.keras.layers.Dense(1, activation = 'sigmoid')\n",
    "prediction_batch = prediction_layer(feature_batch_average)\n",
    "print(prediction_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7cef0199",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape=(160,160, 3))\n",
    "x = data_augmentation(inputs)\n",
    "x = preprocess_input(x)\n",
    "x = base_model(x, training=False)\n",
    "x = global_average_layer(x)\n",
    "x = tf.keras.layers.Dropout(0.2)(x)\n",
    "outputs = prediction_layer(x)\n",
    "model = tf.keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "12cba54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_learning_rate = 0.0001\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=base_learning_rate),\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=False),\n",
    "              metrics=['accuracy', 'binary_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "923df9b0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 160, 160, 3)]     0         \n",
      "_________________________________________________________________\n",
      "sequential (Sequential)      (None, 160, 160, 3)       0         \n",
      "_________________________________________________________________\n",
      "tf.__operators__.getitem (Sl (None, 160, 160, 3)       0         \n",
      "_________________________________________________________________\n",
      "tf.math.add (TFOpLambda)     (None, 160, 160, 3)       0         \n",
      "_________________________________________________________________\n",
      "vgg16 (Functional)           (None, 5, 5, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 14,715,201\n",
      "Trainable params: 513\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d10a0c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e6b69e86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "59/59 [==============================] - 74s 1s/step - loss: 2.2450 - accuracy: 0.5176 - binary_accuracy: 0.5176 - val_loss: 2.0760 - val_accuracy: 0.5279 - val_binary_accuracy: 0.5279\n",
      "Epoch 2/10\n",
      "59/59 [==============================] - 74s 1s/step - loss: 1.8363 - accuracy: 0.4984 - binary_accuracy: 0.4984 - val_loss: 1.7688 - val_accuracy: 0.5236 - val_binary_accuracy: 0.5236\n",
      "Epoch 3/10\n",
      "59/59 [==============================] - 72s 1s/step - loss: 1.6597 - accuracy: 0.5166 - binary_accuracy: 0.5166 - val_loss: 1.6087 - val_accuracy: 0.5408 - val_binary_accuracy: 0.5408\n",
      "Epoch 4/10\n",
      "59/59 [==============================] - 72s 1s/step - loss: 1.6886 - accuracy: 0.5123 - binary_accuracy: 0.5123 - val_loss: 1.4881 - val_accuracy: 0.5365 - val_binary_accuracy: 0.5365\n",
      "Epoch 5/10\n",
      "59/59 [==============================] - 66s 1s/step - loss: 1.5450 - accuracy: 0.5412 - binary_accuracy: 0.5412 - val_loss: 1.3988 - val_accuracy: 0.5494 - val_binary_accuracy: 0.5494\n",
      "Epoch 6/10\n",
      "59/59 [==============================] - 68s 1s/step - loss: 1.4334 - accuracy: 0.5455 - binary_accuracy: 0.5455 - val_loss: 1.3244 - val_accuracy: 0.5494 - val_binary_accuracy: 0.5494\n",
      "Epoch 7/10\n",
      "59/59 [==============================] - 61s 1s/step - loss: 1.3466 - accuracy: 0.5572 - binary_accuracy: 0.5572 - val_loss: 1.2511 - val_accuracy: 0.5579 - val_binary_accuracy: 0.5579\n",
      "Epoch 8/10\n",
      "59/59 [==============================] - 67s 1s/step - loss: 1.2687 - accuracy: 0.5765 - binary_accuracy: 0.5765 - val_loss: 1.1915 - val_accuracy: 0.5579 - val_binary_accuracy: 0.5579\n",
      "Epoch 9/10\n",
      "59/59 [==============================] - 68s 1s/step - loss: 1.1975 - accuracy: 0.5754 - binary_accuracy: 0.5754 - val_loss: 1.1404 - val_accuracy: 0.5665 - val_binary_accuracy: 0.5665\n",
      "Epoch 10/10\n",
      "59/59 [==============================] - 74s 1s/step - loss: 1.2290 - accuracy: 0.5893 - binary_accuracy: 0.5893 - val_loss: 1.1009 - val_accuracy: 0.5751 - val_binary_accuracy: 0.5751\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(ds_train,\n",
    "                    epochs=initial_epochs,\n",
    "                    validation_data=ds_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3818766c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfEAAAHwCAYAAAC2blbYAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8/fFQqAAAACXBIWXMAAAsTAAALEwEAmpwYAABOqElEQVR4nO3deXxU5dn/8c+VyUZIWAMoixJURBQEjOBWxWJbd5RihbqAtlqtex9brbVVa/3p09rW+lSx1N1SqFW0at1XXGoFFFFwQ0CJIPsWIJDl+v1xTsIkTJIJZBhO8n2/Xnkx58x9zlxzovnOuc+Z+zZ3R0RERKInI90FiIiIyPZRiIuIiESUQlxERCSiFOIiIiIRpRAXERGJKIW4iIhIRCnEpVUxs2fMbFxzt00nM1toZsekYL+vmtkPw8dnmNnzybTdjtfZw8xKzSy2vbWKtFYKcdnlhX/gq3+qzGxT3PIZTdmXux/n7g80d9tdkZn93MymJVhfaGZbzOyAZPfl7pPc/dvNVFetDx3u/qW757t7ZXPsP8HrmZnNN7O5qdi/SDopxGWXF/6Bz3f3fOBL4KS4dZOq25lZZvqq3CU9BBxmZkV11o8BPnD3D9NQUzocCXQF+pjZwTvzhfXfpKSaQlwiy8yGm1mJmV1lZl8D95lZRzN7ysyWm9nq8HHPuG3iu4jHm9kbZnZr2HaBmR23nW2LzGyama03sxfN7A4z+1s9dSdT441m9ma4v+fNrDDu+bPM7AszW2lmv6jv+Lh7CfAycFadp84GHmisjjo1jzezN+KWv2VmH5vZWjP7M2Bxz+1lZi+H9a0ws0lm1iF87iFgD+DJsCflZ2bW28y8OvDMrLuZPWFmq8xsnpmdF7fv683sYTN7MDw2c8ysuL5jEBoH/At4Onwc/772N7MXwtdaambXhOtjZnaNmX0evs5MM+tVt9awbd3/Tt40sz+a2Srg+oaOR7hNLzObGv4eVprZn80sJ6xpQFy7rhb0QnVp5P1KK6IQl6jbDegE7AmcT/Df9H3h8h7AJuDPDWw/DPgEKAR+C9xjZrYdbf8OvAN0Bq5n2+CMl0yN3wfOITiDzAauBDCz/sCEcP/dw9dLGLyhB+JrMbN9gUHA5CTr2Eb4geJR4FqCY/E5cHh8E+DmsL79gF4ExwR3P4vavSm/TfASk4GScPvRwP8zsxFxz58MTAE6AE80VLOZ5YX7mBT+jDGz7PC5AuBF4NnwtfYGXgo3/QkwFjgeaAecC2xs6LjEGQbMJ/jd3UQDx8OC+wCeAr4AegM9gCnuvjl8j2fG7Xcs8KK7L0+yDmkN3F0/+onMD7AQOCZ8PBzYAuQ20H4QsDpu+VXgh+Hj8cC8uOfyAAd2a0pbggCsAPLinv8b8Lck31OiGq+NW/4x8Gz4+FcEf+Srn2sbHoNj6tl3HrAOOCxcvgn413YeqzfCx2cDb8e1M4LQ/WE9+z0FeC/R7zBc7h0ey0yCgKsECuKevxm4P3x8PUGQVT/XH9jUwLE9E1ge7jsHWAOcGj43Nr6uOtt9AoxMsL6m1gaO05eN/L5rjgdwaHV9CdoNAxYBGeHyDOB7qf5/TD/R+tGZuETdcncvq14wszwz+0vY3bwOmAZ0sPrvfP66+oG7V59p5TexbXdgVdw6CP74JpRkjV/HPd4YV1P3+H27+wZgZX2vFdb0T+DssNfgDIKz8+05VtXq1uDxy2G37xQz+yrc798IztiTUX0s18et+4LgDLVa3WOTa/Vfex4HPOzuFR6c3U5la5d6L4JehEQaeq4xtX73jRyPXsAX7l5Rdyfu/l9gA3CUmfUj6Cl4YjtrkhZKIS5RV3cavv8B9gWGuXs7gpuaIO6abQosATqFXbfVejXQfkdqXBK/7/A1OzeyzQPA94BvAQUE3bc7UkfdGoza7/dmgt/LwHC/Z9bZZ0NTJy4mOJYFcev2AL5qpKZthNf3vwmcaWZfW3DfxGjg+PCSwCJgr3o2r++5DeG/8b/r3eq0qfv+Gjoei4A9GvgQ8kDY/izgkfgPrCKgEJeWp4Dg2u4aM+sEXJfqF3T3Lwi6Oq83s2wzOxQ4KUU1PgKcaGZHhNd2f03j/x+/TtCNPJGgK37LDtbxb2B/MxsVhs+l1A6yAqA03G8P4Kd1tl8K9Em0Y3dfBLwF3GxmuWY2EPgBwfXspjoL+JTgg8qg8KcvQdf/WIIPM7uZ2eXhjWQFZjYs3PZu4EYz28cCA82sswfXo78i+GAQM7Nzqf+DQLWGjsc7BB+KbjGztuF7jr+/4CHgVIIgf3A7joG0cApxaWluA9oAK4C3CW5a2hnOILi+uRL4DfAPYHM9bW9jO2t09znARQQ30i0BVhOEUkPbOEEA7EntINiuOtx9BXAacAvB+90HeDOuyQ3AEGAtQeBPrbOLm4FrzWyNmV2Z4CXGElx7Xgw8Blzn7i8kU1sd44A73f3r+B/gLmBc2GX/LYIPXF8DnwFHh9v+AXgYeJ7gnoJ7CI4VwHkEQbwS2J/gQ0dD6j0eHnw3/iSCrvIvCX6Xp8c9XwK8S3Am/3rTD4G0dBb8/y0izcnM/gF87O4p7wmQls3M7gUWu/u16a5Fdj0KcZFmYMEgIquABcC3gceBQ939vXTWJdFmZr2BWcBgd1+Q3mpkV5Sy7nQzu9fMlplZwlGhwutMt1swmMNsMxuSqlpEdoLdCL5qVArcDlyoAJcdYWY3Ah8Cv1OAS31SdiZuZkcS/EF70N23GaPZzI4HLiEYTGEY8Cd3H1a3nYiIiCSWsjNxd59G0L1Yn5EEAe/u/jbB91N3T1U9IiIiLU06707vQe1BEUqoPaCDiIiINCCdM+wkGlAiYd++mZ1PMC42bdu2Pahfv36prEtERGSXMnPmzBXuvs3kN+kM8RJqj/LUk+B7odtw94kEA1VQXFzsM2bMSH11IiIiuwgz+yLR+nR2pz9BOJ6zmR0CrHX3JWmsR0REJFJSdiZuZpMJZpkqNLMSgiEdswDc/S6CuX2PB+YRTGJwTqpqERERaYlSFuLuPraR551g+EgRERHZDho7XUREJKIU4iIiIhGlEBcREYkohbiIiEhEKcRFREQiSiEuIiISUQpxERGRiFKIi4iIRJRCXEREJKIU4iIiIhGlEBcREYkohbiIiEhEKcRFREQiSiEuIiISUQpxERGRiFKIi4iIRJRCXEREJKIU4iIiIhGlEBcREYkohbiIiEhEKcRFREQiSiEuIiISUQpxERGRiFKIi4iIRJRCXEREJKIU4iIiIhGlEBcREYkohbiIiEhEKcRFREQiSiEuIiISUSkNcTM71sw+MbN5ZnZ1guc7mtljZjbbzN4xswNSWY+IiEhLkrIQN7MYcAdwHNAfGGtm/es0uwaY5e4DgbOBP6WqHhERkZYmlWfiQ4F57j7f3bcAU4CRddr0B14CcPePgd5m1i2FNYmIiLQYqQzxHsCiuOWScF2894FRAGY2FNgT6JnCmkRERFqMVIa4JVjndZZvATqa2SzgEuA9oGKbHZmdb2YzzGzG8uXLm71QERGRKMpM4b5LgF5xyz2BxfEN3H0dcA6AmRmwIPyhTruJwESA4uLiuh8EREREWqVUnolPB/YxsyIzywbGAE/ENzCzDuFzAD8EpoXBLiIiIo1I2Zm4u1eY2cXAc0AMuNfd55jZBeHzdwH7AQ+aWSUwF/hBquoRERFpaVLZnY67Pw08XWfdXXGP/wPsk8oaREREWiqN2CYiIhJRCnEREZGIUoiLiIhElEJcREQkohTiIiIiEaUQFxERiSiFuIiISEQpxEVERCJKIS4iIhJRCnEREZGIUoiLiIhElEJcREQkohTiIiIiEaUQFxERiSiFuIiISEQpxEVERCJKIS4iIhJRCnEREZGIUoiLiIhElEJcREQkohTiIiIiEaUQFxERiSiFuIiISEQpxEVERCJKIS4iIhJRCnEREZGIUoiLiIhElEJcREQkohTiIiIiEaUQFxERiaiUhriZHWtmn5jZPDO7OsHz7c3sSTN738zmmNk5qaxHRESkJUlZiJtZDLgDOA7oD4w1s/51ml0EzHX3A4HhwO/NLDtVNYmIiLQkqTwTHwrMc/f57r4FmAKMrNPGgQIzMyAfWAVUpLAmERGRFiOVId4DWBS3XBKui/dnYD9gMfABcJm7V6WwJhERkRaj0RA3sxPNbHvC3hKs8zrL3wFmAd2BQcCfzaxdghrON7MZZjZj+fLl21GKiIhIy5NMOI8BPjOz35rZfk3YdwnQK265J8EZd7xzgKkemAcsAPrV3ZG7T3T3Yncv7tKlSxNKEBERabkaDXF3PxMYDHwO3Gdm/wnPjAsa2XQ6sI+ZFYU3q40BnqjT5ktgBICZdQP2BeY38T2IiIi0Skl1k7v7OuBRgpvTdgdOBd41s0sa2KYCuBh4DvgIeNjd55jZBWZ2QdjsRuAwM/sAeAm4yt1XbPe7ERERaUUyG2tgZicB5wJ7AQ8BQ919mZnlEYTz/9W3rbs/DTxdZ91dcY8XA9/evtJFRERat0ZDHDgN+KO7T4tf6e4bzezc1JQlIiIijUkmxK8DllQvmFkboJu7L3T3l1JWmYiIiDQomWvi/wTiv7tdGa4TERGRNEomxDPDEdcACB9raFQREZE0SybEl5vZydULZjYS0B3kIiIiaZbMNfELgElm9meCUdgWAWentCoRERFpVKMh7u6fA4eYWT5g7r4+9WWJiIhIY5I5E8fMTgD2B3KDCcfA3X+dwrpERESkEclMgHIXcDpwCUF3+mnAnimuS0RERBqRzI1th7n72cBqd78BOJTaE5uIiIhIGiQT4mXhvxvNrDtQDhSlriQRERFJRjLXxJ80sw7A74B3CeYE/2sqixIREZHGNRjiZpYBvOTua4BHzewpINfd1+6M4kRERKR+DXanu3sV8Pu45c0KcBERkV1DMtfEnzez71r1d8tERERkl5DMNfGfAG2BCjMrI/iambt7u5RWJiIiIg1KZsS2gp1RiIiIiDRNoyFuZkcmWu/u05q/HBEREUlWMt3pP417nAsMBWYC30xJRSIiIpKUZLrTT4pfNrNewG9TVpGIiIgkJZm70+sqAQ5o7kJERESkaZK5Jv5/BKO0QRD6g4D3U1iTiIiIJCGZa+Iz4h5XAJPd/c0U1SMiIiJJSibEHwHK3L0SwMxiZpbn7htTW5qIiIg0JJlr4i8BbeKW2wAvpqYcERERSVYyIZ7r7qXVC+HjvNSVJCIiIslIJsQ3mNmQ6gUzOwjYlLqSREREJBnJXBO/HPinmS0Ol3cHTk9ZRSIiIpKUZAZ7mW5m/YB9CSY/+djdy1NemYiIiDSo0e50M7sIaOvuH7r7B0C+mf049aWJiIhIQ5K5Jn6eu6+pXnD31cB5yezczI41s0/MbJ6ZXZ3g+Z+a2azw50MzqzSzTklXLyIi0oolE+IZZmbVC2YWA7Ib2yhsdwdwHNAfGGtm/ePbuPvv3H2Quw8Cfg685u6rmlC/iIhIq5VMiD8HPGxmI8zsm8Bk4JkkthsKzHP3+e6+BZgCjGyg/dhw3yIiIpKEZEL8KoIBXy4ELgJmU3vwl/r0ABbFLZeE67ZhZnnAscCjSexXRERESCLE3b0KeBuYDxQDI4CPkti3JVjnCdYBnAS8WV9Xupmdb2YzzGzG8uXLk3hpERGRlq/er5iZWV9gDEE390rgHwDufnSS+y4BesUt9wQW19N2DA10pbv7RGAiQHFxcX0fBERERFqVhs7EPyY46z7J3Y9w9/8DKpuw7+nAPmZWZGbZBEH9RN1GZtYeOAr4VxP2LSIi0uo1FOLfBb4GXjGzv5rZCBJ3kSfk7hXAxQQ3xn0EPOzuc8zsAjO7IK7pqcDz7r6h6eWLiIi0XubecO+0mbUFTiHoVv8m8ADwmLs/n/LqEiguLvYZM2Y03lBERKSFMLOZ7l5cd30yN7ZtcPdJ7n4iwXXtWcA2A7eIiIjIzpXMV8xquPsqd/+Lu38zVQWJiIhIcpoU4iIiIrLrUIiLiIhElEJcREQkohTiIiIiEaUQFxERiSiFuIiISEQpxEVERCJKIS4iIhJRCnEREZGIUoiLiIhElEJcREQkohTiIiIiEaUQFxERiSiFuIiISEQpxEVERCJKIS4iIhJRCnEREZGIUoiLiIhElEJcREQkohTiIiIiEaUQFxERiSiFuIiISEQpxEVERCJKIS4iIhJRCnEREZGIUoiLiIhElEJcREQkohTiIiIiEZXSEDezY83sEzObZ2ZX19NmuJnNMrM5ZvZaKusRERFpSTJTtWMziwF3AN8CSoDpZvaEu8+Na9MBuBM41t2/NLOuqapHRESkpUnlmfhQYJ67z3f3LcAUYGSdNt8Hprr7lwDuviyF9YiIiLQoqQzxHsCiuOWScF28vkBHM3vVzGaa2dkprEdERKRFSVl3OmAJ1nmC1z8IGAG0Af5jZm+7+6e1dmR2PnA+wB577JGCUkVERKInlWfiJUCvuOWewOIEbZ519w3uvgKYBhxYd0fuPtHdi929uEuXLikrWEREJEpSGeLTgX3MrMjMsoExwBN12vwL+IaZZZpZHjAM+CiFNYmIiLQYKetOd/cKM7sYeA6IAfe6+xwzuyB8/i53/8jMngVmA1XA3e7+YapqEhERaW5VVc6y9Zv5as1GSlZvYsnaMn50ZB/MEl1Vbl7mXvcy9a6tuLjYZ8yYke4yRER2SHl5OSUlJZSVlaW7FGmEu1NZFfxUVCV47E7dKN29fS6xjKaHeG5uLj179iQrK6vWejOb6e7Fddun8sY2ERGpR0lJCQUFBfTu3XunnLFJ/SqrqthS4ZRXVrGlsir4t6KK8kpnS2UVFZVVQHD9OTvcJiuWQVYsg+xYBlmZFv4bLscytivA3Z2VK1dSUlJCUVFRUtsoxEVE0qCsrEwBvhO4B2fMQSiHAV3plFeEgV1RRWWd02izMJRjRrucTLIytwZ2dqaRGcsgIwW/NzOjc+fOLF++POltFOIiImmiAN9xVR6cQQeh7HFn0VsDu+5l41iG1YRy25xMsmMWd1adQWaGpe1309TXVYiLiLRgVR6chZaVV1JR5TUDeKxauZJRJx0HwLKlS4nFYnQuLATgpWlvkpOdDWZbB/ywrYN/vDdzJpMn/Y1b/3hbzetUZ4/FNT76yCN4ddobwTqLe26b9rWfj29f5dQE80//5wqeeHwq/3n/UyrC9eVhV3e86q7uNlkx2rXJqBXQ2TEjltFy5v7SjW0iImnw0Ucfsd9++zXb/uLDenP1v+VVbK6owrcZZ6u2CX+4hby8toy74JKadRUVFWRm7jrneVVVVRx36EC6dNudK6+9niO+cVQQzjVd3cHZdFbmjnV1V1ZWEovFaq/0KqiqhKqKuH/jHnsFVFYG/1av67o/bOeHhUT/bejGNhGRFiDZsM7OzCA3M0ZBm0xys2LkZmaQGYsLFa8eQtPpnJ9NftscfnfNZXTs1JH3Z81i0KDBfPe00/jZlf/Dpk2baNOmDRMm3k3fvvsy7bXX+NNtf+CRqY9z029+TcmiRSxcsIBFixZx4cWXcMGPLwKHHl07UbJsFa9Pe43/vek3dOrcmY/mzmHQ4MFMuPt+zIznn3uWX/38Z3Tq3JmBBw7mi4UL+Ns/p9bUZwbZsQzeeO1VBg0cwOmnn86bzz3B2aNOAGDp0qX84IILmD9/PgATJkzgsMMO48EHH+TWW2/FzBg4cCAPPfQQ48eP58Tjj2f0qJFQVUF+p26ULvuSV1+bxg03/47du3Vh1uw5zH3rGU458wIWLV5CWVkZl/1gLOef+V0Ann3lTa655Q4qKysp7NSBF6bcxb5HnspbT/2dLl27UpWRRd9DjuPtt/9LYdduKf/vQSEuIpJmNzw5h7mL122zvsqdKg9uzqpyp6oqWBfPzMgwyMgwMqofm9G/ezuuO2n/pF4/MyMI+FiGMX/ePF5+6SVisRjr1q3jjddfJzMzkxdffJHfXP8rHn30Udpkx8jMMPJzs8jJjPH5Z5/yyiuvsH79evbdd19+cunFNV+R6pCXTUFuFh/MnsWcOXPo3r07hx9+OB+/P4Pi4mJ+dvnFTJs2jaKiIsaOHUt2ZgZdC3K3qfHxRx/m+9//PiNHjuQXv/gF5Vs2kxXL4NKLL+Koww/hsb/fR2X5ZkrXrWPOf1/mphtv4M2n/0Fhx3asWrkSvv4ANq6CNV/AsnAyTa8Kljcs550Z7/LhK49S1HtPqKrk3v/7Xzp17symzeUc/M2T+O6Ys6gig/OuuoVpLz1P0V57s2rNWjI6F3LmuHOZ9Px0Lr/8cl58/nkOHHzQTglwUIiLiKRVlW/9znEyYZ0V3hldHdbN7bTTTqvpTl67di3jxo3js88+w8woLy9PuM0JJ5xATk4OOTk5dO3alaVLl9KzZ89abYYOHVqzbtCgQSxcuJD8/Hz69OlD0Z57QMVmxo4excR77gnC1rd2X28p28jTTz3JH39xIQWbFjHswH48P+UvnHDMN3j55Zd48Lc/hdULiAHtM+DBF55j9PEjKGzfFjA6dekGGZmQlQt5HaHDHmCZYBnQZT/ouJKhww6haNjxNfXefsf1PPbYYwAs+moJny1ezfLlyznyqKMo2rc/AJ0Kg2HAzz33XEaOHMnll1/OvffeyznnnNOcv5IGKcRFRHaC8soqFq7YwKdLS/ls2XoO7rCFT79ez+aKKkYf1JPRBwXtqrvBc7IyarrBczJjZGzH9463R9u2bWse//KXv+Too4/mscceY+HChQwfPjzhNjk5OcEDd2KxDCo2bYDNpcG6jSth0ypyYg5rvoSqCmJb1lOx6kt8eQ5sKYWvZwdt138FWzYEZ8fVLMazL0xj7fr1DDgqmM1646Yy8go6cMKosZARg059oE3b4HFGJl4wDSvLgq61rytntmlHVXY7yOuMu7Nly5Yg2GOZtd73q6++yosvvsh//vMf8vLyGD58OGVlZbh7wrvHe/XqRbdu3Xj55Zf573//y6RJk5p41LefQlxEpBlVh/Vny0r5dOl6PgtDe8GKDZRXBmfXZnDvyO5kZ2bUuma9M8O6UVWVrF2zmh7dCmHzeu7/64Sg+3n911C6HMo3wcrPYcMK8FJYMjs4e67YDKvmQduNYXf1l7BhJVRsgbK1wRkxQEYm/Q44kPmLlrBwVQW9i4r4x7NvQnZb6NIvaJcRA8tg8jM3c/fd9zB27FgANmzYQFFRERsz2jJixDFMuG8Sl19+OZWVlWwo3cCIY47h1FNP5YorrqBz586sWrWKTp060bt3b2bOnMn3vvc9/vWvf9Xbs7B27Vo6duxIXl4eH3/8MW+//TYAhx56KBdddBELFiygqKioZr8AP/zhDznzzDM566yztr0xLoUU4iIiyaqqhE1rYNMqyjdvZPGaTXy5aiNfrtzAl6s28cWqDSxevYmKqrAr3GD3drkc3imPsXu0Zc/ObdijU1t6dsxjwVqjdzsjuH2rImhfkeo34NveWV1VAZtWg5UFIbvmS1g8C3B+du6pjLv85/zh1t/yzcMPDtquXwKb14bblgdd0rHsoJvaMiEjC9r1CM6OLQO69odOqyC3Hew2ICijTQfI70qb3fty54S/cOzosygsLGTo0KEQWwpZbWoq3rhxI8899xx/+ctfata1bduWI444gieffJI//elPnH/++dxzzz3EYjEmTJjAoYceyi9+8QuOOuooYrEYgwcP5v777+e8885j5MiRDB06lBEjRtQ6+4537LHHctdddzFw4ED23XdfDjnkEAC6dOnCxIkTGTVqFFVVVXTt2pUXXngBgJNPPplzzjlnp3alg75iJiKt1ZaNsGlVcP211r+rKS9dQdm6FVSUrsA3riJWtprsLWvIqSwlo5GvayXro+88zH57dm2Wfe2QmjPezK2Pa/2b4LE13/esS0tLyc/Px9256KKL2Geffbjiiiuabf87y4wZM7jiiit4/fXXd3hf+oqZiLQeVVVQtiZBGG/7b9XGVVRtWEVG2SoyKjfXu8vNnsta8lnt+az2AtbQk/W2H+U5HfE2Hclo25mC/Hbs3qEN3Tu0Ybd2ueRkNjHYyrtAx+TGx242llE7pC22ddSVNPnrX//KAw88wJYtWxg8eDA/+tGP0lrP9rjllluYMGHCTr0WXk1n4iKy6ygvayCIVydeX7YmuPaaQCUxNmQUsIZ8Vla1ZUVlGMzks8YLWE0+660A8jqRld+ZnHZdyO/Qhc4dCuhWkEu3drns1j6Hru1yKcjJbNahOJt7sBdpOXQmLtKSVWyGdYvDn69gbcnWx+u+CoIwUnxr13b5xnpbVcbaUJbVng2xdqyzAlZ7D5ZV9eVry6OkvA2rq4KwDkK6gLXk0ya/A13b59G1IJdu7XLYrV0QzPu2y6Fb+LhDm6xd52YykSZSiIvsSio2BzcOrf0qDOYwoNd+tTWkNySY4Si3Q3AzUbvuwd29uxAHKqu85vvQ1fMvV1ZBVfh4U242a9rls6KyLV+X5/HVljwWbcphwcYcVlTms4Z8NtdMAgmF+dlBMBcGYdy1XS57t8upOXvu1i6Hzvk52zUdpEiUKMRFdpaKLUFArwsDuu4Z9NqvYMOybbfLbQ/tegYB3X1QGNZhYLfvuV3BXVXlNUN2biqvjPs3WBe/vKm8ks3llWzaUklZRSWbtlRRVlFZ066svCruuWAo0LrLyWrfJotu7XLo1j6Xrj1zOarmjDno0u7WLpcu+TlkN/X6s0gLpRCX1Ckvg9ULYOU8WLUgWJfVJvjJzIWsvGCghay8epbbBDffREFlee0u7upQrn68bjGULoO6dzbntIf2YSDvNjAI5+rl6uDOyW/05VeWbuadBav474JVLFtfFoRoGMDxYbs9wRovlmG0yYqRWz0QSVasZjk/J5PC/Jya5Tbh81vbBdu0yY6Rkxn8m5sZrOuYl03XdjnkZkXk9y2yi1CIy46pqoS1i4KgXvl5+G/4s2YR24RWU8Wyw9Bvs/UDQK3lRj4EbNO+7nK4TWab+mccqiwPz6DrOXtetxhKl277XnPabT1j3m1A4jPonILtOizVof32/JW8PX8VnyxdD0BedozuHdrUBGlBbiZdCpoerG2ywzaZMXKzM2rCOiumM+CWYvjw4fz85z/nO9/5Ts262267jU8//ZQ777yz3m1uvfVWiouLOf744/n73/9Ohw4darW5/vrryc/P58orr6z3tR9//HH69u1L//7B8KW/+tWvOPLIIznmmGN2/I0Bl112GY888giLFi0iowVNO5qIQlwa5x5ch40P6OrAXjUfKrdsbZtdAIV7Q69hMOgM6Lw3dN4rHPghFozyVLEp+Lf6Z5vlsuAGp/Lw34TLm4LhHGttHz5flXgUpkbFcuoEfW5w93OigM4u2HrG3G3/uDPouKDObbfdh7yuhkK7uHcnRg7uziF9OjOgR3sFrSRl7NixTJkypVaIT5kyhd/97ndJbf/0009v92s//vjjnHjiiTUh/utf/3q791VXVVUVjz32GL169WLatGn1DhW7oxJOWZoGCnHZavP6uLPpz2sH9ua1W9vFsoNQ7rw39P1OGNThT9suDX/vNImu4R1WWREGeyMfAur7EBHfpseQrcEcH9LNGNCJKLQl1UaPHs21117L5s2bycnJYeHChSxevJgjjjiCCy+8kOnTp7Np0yZGjx7NDTfcsM32vXv3ZsaMGRQWFnLTTTfx4IMP0qtXL7p06cJBBwUDwf/1r39l4sSJbNmyhb333puHHnqIWbNm8cQTT/Daa6/xm9/8hkcffZQbb7yRE088kdGjR/PSSy9x5ZVXUlFRwcEHH8yECRPIycmhd+/ejBs3jieffJLy8nL++c9/0q9fv23qeuWVVzjggAM4/fTTmTx5ck2IL126lAuaMmVpWA9Afn4+paWlvPrqq9xwww3svvvuzJo1i7lz53LKKaewaNGiYMrSyy7j/PPPB+DZZ5/lmmuuCaYsLSzkhRdeYN999+Wtt96iS5cuVFVV0bdvX95++20KCwu3+/eoEG9tKrbA6oWJz6pLv45raNC+V3AWPfB7cUG9VzAD0K58rTqWCbGC7e6qTgeFdiv3zNXBVJnNabcBcNwt9T7duXNnhg4dyrPPPsvIkSOZMmUKp59+OmbGTTfdRKdOnaisrGTEiBHMnj2bgQMHJtzPzJkzmTJlCu+99x4VFRUMGTKkJsRHjRrFeeedB8C1117LPffcwyWXXMLJJ59cKySrlZWVMX78eF566SX69u3L2WefzYQJE7j88ssBKCws5N133+XOO+/k1ltv5e67796mnsmTJzN27FhGjhzJNddcQ3l5OVlZWVx66aUcddRRPPbYY1RWVlJaWsqcOXO46aabePPNNyksLGTVqlWNHtZ33nmHDz/8kKKiYKCee++9l06dOrFp0yYOPvhgvvvd71JVVcV5551XM8XqqlWryMjI4Mwzz2TSpGCc9xdffJEDDzxwhwIcWnuIr1kEc6Y28RpqBG62qqoKrtfWDemV84LZgeIHxsgrDMJ572OCgK4O605FtcYvlual0JZdQXWXenWI33vvvQA8/PDDTJw4kYqKCpYsWcLcuXPrDfHXX3+dU089lby8PCAYQ7zahx9+yLXXXsuaNWsoLS2t1XWfyCeffEJRURF9+/YFYNy4cdxxxx01IT5q1CgADjroIKZOnbrN9lu2bOHpp5/mj3/8IwUFBQwbNoznn3+eE044gZdffpkHH3wQgFgsRvv27XnwwQcZPXp0TZBWT2bSkKFDh9YEOMDtt9++dcrSRYv47LPPgilLjzyypl31flMxZWnrDvGVn8ELv2r6drHsRm6sauRDQHPdnb1xVZ0z6urA/jzoIq6WlRcEdPdBMGB07bPqNh2b/v6lyRTa0qAGzphT6ZRTTuEnP/kJ7777Lps2bWLIkCEsWLCAW2+9lenTp9OxY0fGjx9PWVnDAwjVN5Ld+PHjefzxxznwwAO5//77efXVVxvcT2MjiFZPeRqLxaio2Ha2mGeffZa1a9cyYEAw0crGjRvJy8vjhBNOqPf1EtWemZlJVVVVTZstW7be97OrTVnaukO8aDj8/KtmvtlqVeLtt/tmqwR3Z2dkBneEb1q9tV1GJnTsHYRzn+G1z6oLdk/7+MitjUJboiA/P5/hw4dz7rnn1kzzuW7dOtq2bUv79u1ZunQpzzzzTIM3hx155JGMHz+eq6++moqKCp588sma8c/Xr1/P7rvvTnl5OZMmTaJHjx4AFBQUsH79+m321a9fPxYuXMi8efNqrqEfddRRSb+fyZMnc/fdd287ZenGjYwYMaKma76yspINGzYwYsSIyE9Z2rpDPCMjuNFqp95s1QwfFCq3QI+DtoZ04T7BdepYVurfhyRUX2i3yYpR3LsjJw8KQntgT4W27FrGjh3LqFGjmDJlCgAHHngggwcPZv/996dPnz4cfvjhDW4/ZMgQTj/9dAYNGsSee+7JN77xjZrnbrzxRoYNG8aee+7JgAEDaoJ7zJgxnHfeedx+++088sgjNe1zc3O57777OO2002pubLvggguSeh+tdcrSVj0ByrJ1ZUx97yv6dstnn64F9OjQRmMop0hFZRUZZi3m+DYW2of06azQlgZpApTWKZkpSzUBSpLmLlnHLc98XLOclx1j76757N01n77dChTu22H1hi18vryUz5eXMm9ZKZ8v38Dny0tZtGojVQ7ZmRn1DDyydblNVoycBOu2HSUsRpvsjK2DlMS3y4w16+9MZ9oisqNSMWVpqz4TB1i7qZx5y9bz6dJSPltaymfL1vPp0vUsXbd1rmGFe21VVc5XazYxb3kpny8LAvvzZUFYr9yw9QaQ7MwM+hS2Za+u+fQpbEssw8JxuGuPrV1WUUVZreVgfO7N5cHj8srt+280OzOj1uhj1R8OakYpa+BDRG5WBlmxDD5ask5n2pISOhOX+uhMvAnat8nioD07cdCetb9akCjc35y3gqnvflXTpjrc9+lawD7d8ltcuJeVVzI/PJOOP7Oev7y01tjbndpms1eXtnyrfzf27prPXl2Cnx4d2zTLLFIVlVWUVU+qET/pRq2JOhKvr+8Dw6oNW7b5wLCpvJKKqtofGHSmLSK7spSGuJkdC/wJiAF3u/stdZ4fDvwLCGfHYKq7N9/4ezug3nDfWM685UG4f7p0PfOWlfLGvOU8+m5JTZuohfvK0s013d7zqs+sl5dSsnoT1R01ZtCrYx57dWnL4Xt1DsI6DOxObbMbfoEdlBnLID8WTLCRauWVVVsnCymvZLf2uQptSZn6vookrVdTe8dT9lfRzGLAHcC3gBJgupk94e5z6zR93d1PTFUdza19Xv3h/tmy9Xy2LAj3z5buWuFeWeWUrN5Y0/UdH9arN279+kRuVgZ9CvMZ1Ksjo4f0Yq+ubdmrSz5FhW1bxQxTWbGgG70gN92VSEuXm5vLypUr6dy5s4JcgCDAV65cSW5u8n+AUnlqMxSY5+7zAcxsCjASqBviLUL7vCyKe3eiuHd6w33jloq4LvANNdes56/YwJa4LvDC/Gz6dMnn2AN2D7vAg7DeVXsLRFqanj17UlJSwvLly9NdiuxCcnNz6dmzZ9LtUxniPYBFccslwLAE7Q41s/eBxcCV7j4nhTXtdI2F+6fh9fbPlpby+mf1h3vfbvnsExfuKxPdBb6slK/WbB2pLcNgj0557NUlnyP7dmHvLvk1Z9Yd8lLbBS4iDcvKyqo1fKfI9khliCc6navb2f8usKe7l5rZ8cDjwD7b7MjsfOB8gD322KOZy0yPZMK9+pp73XDPzLBaN2C1yYqxV9e2FPfuyJguvWquVfcuzCMns+V3gYuItFapDPESoFfcck+Cs+0a7r4u7vHTZnanmRW6+4o67SYCEyH4ilnqSk6/ZML9i1Ub2K1dbnAXeNd8dm+Xqy5wEZFWKJUhPh3Yx8yKgK+AMcD34xuY2W7AUnd3MxsKZAArU1hTZNUX7iIi0nqlLMTdvcLMLgaeI/iK2b3uPsfMLgifvwsYDVxoZhXAJmCMN3J//cyZM1eY2RfNWGohsKLRVtIcdKx3Dh3nnUPHeefQcQ7smWhl5EZsa25mNiPRKDjS/HSsdw4d551Dx3nn0HFumEaxEBERiSiFuIiISEQpxMO73mWn0LHeOXScdw4d551Dx7kBrf6auIiISFTpTFxERCSiWnWIm9mxZvaJmc0zs6vTXU9LZGa9zOwVM/vIzOaY2WXprqklM7OYmb1nZk+lu5aWzMw6mNkjZvZx+N/2oemuqSUysyvCvxsfmtlkM9PURHW02hCPm2XtOKA/MNbM+qe3qhapAvgfd98POAS4SMc5pS4DPkp3Ea3An4Bn3b0fcCA65s3OzHoAlwLF7n4AwXgjY9Jb1a6n1YY4cbOsufsWoHqWNWlG7r7E3d8NH68n+GPXI71VtUxm1hM4Abg73bW0ZGbWDjgSuAfA3be4+5q0FtVyZQJtzCwTyKPO0N3SukM80SxrCpcUMrPewGDgv2kupaW6DfgZUNVIO9kxfYDlwH3hpYu7zaxtuotqadz9K+BW4EtgCbDW3Z9Pb1W7ntYc4snMsibNxMzygUeBy+MnvpHmYWYnAsvcfWa6a2kFMoEhwAR3HwxsAHRPTTMzs44EvaNFQHegrZmdmd6qdj2tOcQbnWVNmoeZZREE+CR3n5ruelqow4GTzWwhwaWhb5rZ39JbUotVApS4e3WP0iMEoS7N6xhggbsvd/dyYCpwWJpr2uW05hCvmWXNzLIJbph4Is01tThmZgTXDj9y9z+ku56Wyt1/7u493b03wX/LL7u7zlpSwN2/BhaZ2b7hqhHA3DSW1FJ9CRxiZnnh35ER6AbCbaRyKtJdWn2zrKW5rJbocOAs4AMzmxWuu8bdn05fSSI77BJgUngCMB84J831tDju/l8zewR4l+BbLu+h0du2oRHbREREIqo1d6eLiIhEmkJcREQkohTiIiIiEaUQFxERiSiFuIiISEQpxEVERCJKIS4iIhJRCnGRJJjZM2Y2rrnbppOZLTSzY1Kw31fN7Ifh4zPMrN5JK+Lbbsfr7GFmpeG0wiKtkkJcWqzwD3z1T5WZbYpbPqMp+3L349z9geZuuysys5+b2bQE6wvNbIuZHZDsvtx9krt/u5nqqvWhw92/dPd8d69sjv3XeS03s72be78izU0hLi1W+Ac+393zCcZhPilu3aTqduFcxbLVQ8BhZlZUZ/0Y4AN3/zANNYlIAgpxaXXMbLiZlZjZVWb2NcG80B3N7CkzW25mq8PHPeO2ie8iHm9mb5jZrWHbBWZ23Ha2LTKzaWa23sxeNLM76pt9LMkabzSzN8P9PW9mhXHPn2VmX5jZSjP7RX3Hx91LgJcJxryPdzbwQGN11Kl5vJm9Ebf8LTP72MzWmtmfiZsS2Mz2MrOXw/pWmNkkM+sQPvcQsAfwZNiT8jMz6x2eMWeGbbqb2RNmtsrM5pnZeXH7vt7MHjazB8NjM8fMius7BvUxs/bhPpaHx/JaM8sIn9vbzF4L39sKM/tHuN7M7I9mtix8bnZTejNEGqIQl9ZqN6ATsCdwPsH/C/eFy3sAm4A/N7D9MOAToBD4LXCPmSWao76xtn8H3gE6A9ezbXDGS6bG7xNMxtEVyAauBDCz/sCEcP/dw9dLGLyhB+JrsWDGrkHA5CTr2Eb4geJR4FqCY/E5wQQ5NU2Am8P69iOYKvh6AHc/i9q9Kb9N8BKTCaYJ7Q6MBv6fmY2Ie/5kgmlaOxDMWNhozQn8H9Ae6AMcRfDBpnrykxuB54GOBMf2/8L13waOBPqGr306sHI7XltkGwpxaa2qgOvcfbO7b3L3le7+qLtvdPf1wE0Ef6Tr84W7/zW8HvsAsDvQrSltzWwP4GDgV+6+xd3foIHpcJOs8T53/9TdNwEPEwQvBKH2lLtPc/fNwC/DY1Cfx8Iaq+dvPht4JpzbuanHqtrxwFx3fyScH/o24Ou49zfP3V8IfyfLgT8kuV/MrBdwBHCVu5e5+yzgbmp/KHrD3Z8Ofw8PAQcms++414gRBPDP3X29uy8Efh/3GuUEH2y6hzW8Ebe+AOhHMOnUR+6+pCmvLVIfhbi0Vsvdvax6wYI5i/8SdpGuA6YBHaz+O5/jw2dj+DC/iW27A6vi1gEsqq/gJGv8Ou7xxriausfv29030MDZYFjTP4Gzw16DMwg+gGzPsapWtwaPXzazrmY2xcy+Cvf7N4Iz9mRUH8v1ceu+AHrELdc9NrnWtPshCgl6N76o5zV+RtCb8E7YXX8ugLu/THDWfwew1Mwmmlm7JryuSL0U4tJa1Z2D93+AfYFh7t6OoPsT4q7ZpsASoJOZ5cWt69VA+x2pcUn8vsPX7NzINg8A3wO+RXAm+dQO1lG3BqP2+72Z4PcyMNzvmXX22dC8yYsJjmVB3Lo9gK8aqakpVrD1bHub13D3r939PHfvDvwIuNPCO9zd/XZ3PwjYn6Bb/afNWJe0YgpxkUABwbXdNWbWCbgu1S/o7l8AM4DrzSzbzA4FTkpRjY8AJ5rZEWaWDfyaxv//fx1YA0wEprj7lh2s49/A/mY2KjwDvpTg3oRqBUBpuN8ebBt0SwmuRW/D3RcBbwE3m1mumQ0EfgBMStQ+SdnhvnLNLDdc9zBwk5kVmNmewE8Iegwws9PibvBbTfCho9LMDjazYWaWBWwAyoBm/1qctE4KcZHAbUAbgrOtt4Fnd9LrngEcStC1/RvgH8DmetrexnbW6O5zgIsIbqRbQhAyJY1s48CDBGeeD+5oHe6+AjgNuIXg/e4DvBnX5AZgCLCWIPCn1tnFzcC1ZrbGzK5M8BJjgd4EZ+WPEdzz8EIytdVjDsGHleqfc4BLCIJ4PvAGwfG8N2x/MPBfMysluLfhMndfALQD/kpwzL8geO+37kBdIjUs+P9URHYF4deSPnb3lPcEiEj06UxcJI3Crta9zCzDzI4FRgKPp7ksEYmIlIW4md0bDm6QcHSncACE28NBGWab2ZBU1SKyC9sNeJXgWvDtwIXu/l5aKxKRyEhZd7qZHUnwh+lBd99mdCIzO57g+tLxBINh/Mndh6WkGBERkRYoZWfi7j4NWNVAk5EEAe/u/jbB90x3T1U9IiIiLU06r4n3oPbAFiXUHphBREREGpDO2ZsSDQyRsG/fzM4nGN+atm3bHtSvX79U1iUiIrJLmTlz5gp371J3fTpDvITaozX1JPh+5zbcfSLBgBMUFxf7jBkzUl+diIjILsLMvki0Pp3d6U8QjstsZocAazUpgIiISPJSdiZuZpOB4UChmZUQDM2YBeDudwFPE9yZPo9gMoJzEu9JREREEklZiLv72Eaed4JhIEVERGQ7pPOauIiIpEh5eTklJSWUlZU13lh2Gbm5ufTs2ZOsrKyk2ivERURaoJKSEgoKCujduzfBrK+yq3N3Vq5cSUlJCUVFRUlto7HTRURaoLKyMjp37qwAjxAzo3Pnzk3qPVGIi4i0UArw6Gnq70whLiIizW7lypUMGjSIQYMGsdtuu9GjR4+a5S1btjS47YwZM7j00ksbfY3DDjusWWp99dVXOfHEE5tlXzubromLiEiz69y5M7NmzQLg+uuvJz8/nyuvvLLm+YqKCjIzE0dQcXExxcXFjb7GW2+91Sy1RpnOxEVEZKcYP348P/nJTzj66KO56qqreOeddzjssMMYPHgwhx12GJ988glQ+8z4+uuv59xzz2X48OH06dOH22+/vWZ/+fn5Ne2HDx/O6NGj6devH2eccQbVM3Q+/fTT9OvXjyOOOIJLL720SWfckydPZsCAARxwwAFcddVVAFRWVjJ+/HgOOOAABgwYwB//+EcAbr/9dvr378/AgQMZM2bMjh+sJOlMXEREdppPP/2UF198kVgsxrp165g2bRqZmZm8+OKLXHPNNTz66KPbbPPxxx/zyiuvsH79evbdd18uvPDCbb6C9d577zFnzhy6d+/O4YcfzptvvklxcTE/+tGPmDZtGkVFRYwd2+DwJbUsXryYq666ipkzZ9KxY0e+/e1v8/jjj9OrVy+++uorPvzwQwDWrFkDwC233MKCBQvIycmpWbczKMRFRFq4G56cw9zF65p1n/27t+O6k/Zv8nannXYasVgMgLVr1zJu3Dg+++wzzIzy8vKE25xwwgnk5OSQk5ND165dWbp0KT179qzVZujQoTXrBg0axMKFC8nPz6dPnz41X9caO3YsEydOTKrO6dOnM3z4cLp0CeYcOeOMM5g2bRq//OUvmT9/PpdccgknnHAC3/72twEYOHAgZ5xxBqeccgqnnHJKk4/L9lJ3uoiI7DRt27atefzLX/6So48+mg8//JAnn3yy3q9W5eTk1DyOxWJUVFQk1aa6S3171Ldtx44def/99xk+fDh33HEHP/zhDwH497//zUUXXcTMmTM56KCDEtaYCjoTFxFp4bbnjHlnWLt2LT169ADg/vvvb/b99+vXj/nz57Nw4UJ69+7NP/7xj6S3HTZsGJdddhkrVqygY8eOTJ48mUsuuYQVK1aQnZ3Nd7/7Xfbaay/Gjx9PVVUVixYt4uijj+aII47g73//O6WlpXTo0KHZ31NdCnEREUmLn/3sZ4wbN44//OEPfPOb32z2/bdp04Y777yTY489lsLCQoYOHVpv25deeqlWF/0///lPbr75Zo4++mjcneOPP56RI0fy/vvvc84551BVVQXAzTffTGVlJWeeeSZr167F3bniiit2SoAD2I50N6SD5hMXEWncRx99xH777ZfuMtKutLSU/Px83J2LLrqIffbZhyuuuCLdZTUo0e/OzGa6+zbfu9M1cRERabH++te/MmjQIPbff3/Wrl3Lj370o3SX1KzUnS4iIi3WFVdcscufee8InYmLiIhElEJcREQkohTiIiIiEaUQFxERiSiFuIiINLvhw4fz3HPP1Vp322238eMf/7jBbaq/Qnz88ccnHIP8+uuv59Zbb23wtR9//HHmzp1bs/yrX/2KF198sQnVJ7YrTlmqEBcRkWY3duxYpkyZUmvdlClTkp6E5Omnn97uAVPqhvivf/1rjjnmmO3a165OIS4iIs1u9OjRPPXUU2zevBmAhQsXsnjxYo444gguvPBCiouL2X///bnuuusSbt+7d29WrFgBwE033cS+++7LMcccUzNdKQTfAT/44IM58MAD+e53v8vGjRt56623eOKJJ/jpT3/KoEGD+Pzzzxk/fjyPPPIIEIzMNnjwYAYMGMC5555bU1/v3r257rrrGDJkCAMGDODjjz9O+r2mc8pShbiIiDS7zp07M3ToUJ599lkgOAs//fTTMTNuuukmZsyYwezZs3nttdeYPXt2vfuZOXMmU6ZM4b333mPq1KlMnz695rlRo0Yxffp03n//ffbbbz/uueceDjvsME4++WR+97vfMWvWLPbaa6+a9mVlZYwfP55//OMffPDBB1RUVDBhwoSa5wsLC3n33Xe58MILG+2yr1Y9ZenLL7/MrFmzmD59Oo8//jizZs2qmbL0gw8+4JxzzgGCKUvfe+89Zs+ezV133dWkY5qIBnsREWnpnrkavv6gefe52wA47pYGm1R3qY8cOZIpU6Zw7733AvDwww8zceJEKioqWLJkCXPnzmXgwIEJ9/H6669z6qmnkpeXB8DJJ59c89yHH37Itddey5o1aygtLeU73/lOg/V88sknFBUV0bdvXwDGjRvHHXfcweWXXw4EHwoADjroIKZOndr4MSD9U5bqTFxERFLilFNO4aWXXuLdd99l06ZNDBkyhAULFnDrrbfy0ksvMXv2bE444YR6pyCtZmYJ148fP54///nPfPDBB1x33XWN7qexuUKqpzOtb7rTpuxzZ01ZqjNxEZGWrpEz5lTJz89n+PDhnHvuuTU3tK1bt462bdvSvn17li5dyjPPPMPw4cPr3ceRRx7J+PHjufrqq6moqODJJ5+sGf98/fr17L777pSXlzNp0qSaaU0LCgpYv379Nvvq168fCxcuZN68eey999489NBDHHXUUTv0HtM9ZalCXEREUmbs2LGMGjWq5k71Aw88kMGDB7P//vvTp08fDj/88Aa3HzJkCKeffjqDBg1izz335Bvf+EbNczfeeCPDhg1jzz33ZMCAATXBPWbMGM477zxuv/32mhvaAHJzc7nvvvs47bTTqKio4OCDD+aCCy5o0vvZ1aYs1VSkIiItkKYijS5NRSoiItIKKMRFREQiSiEuIiISUSkNcTM71sw+MbN5ZnZ1gufbm9mTZva+mc0xs3NSWY+ISGsStXuepOm/s5SFuJnFgDuA44D+wFgz61+n2UXAXHc/EBgO/N7MslNVk4hIa5Gbm8vKlSsV5BHi7qxcuZLc3Nykt0nlV8yGAvPcfT6AmU0BRgJz49o4UGDBN/nzgVXAjn3zXURE6NmzJyUlJSxfvjzdpUgT5Obm1voKW2NSGeI9gEVxyyXAsDpt/gw8ASwGCoDT3b0qhTWJiLQKWVlZFBUVpbsMSbFUXhNPNE5e3X6d7wCzgO7AIODPZtZumx2ZnW9mM8xshj5VioiIBFIZ4iVAr7jlngRn3PHOAaZ6YB6wAOhXd0fuPtHdi929uHqQeRERkdYulSE+HdjHzIrCm9XGEHSdx/sSGAFgZt2AfYH5KaxJRESkxUjZNXF3rzCzi4HngBhwr7vPMbMLwufvAm4E7jezDwi6369y9xWpqklERKQlSekEKO7+NPB0nXV3xT1eDHw7lTWIiIi0VBqxTUREJKIU4iIiIhGlEBcREYkohbiIiEhEKcRFREQiSiEuIiISUQpxERGRiFKIi4iIRJRCXEREJKIU4iIiIhGlEBcREYkohbiIiEhEKcRFREQiSiEuIiISUQpxERGRiFKIi4iIRJRCXEREJKIU4iIiIhGlEBcREYkohbiIiEhEKcRFREQiqtEQN7OLzazjzihGREREkpfMmfhuwHQze9jMjjUzS3VRIiIi0rhGQ9zdrwX2Ae4BxgOfmdn/M7O9UlybiIiINCCpa+Lu7sDX4U8F0BF4xMx+m8LaREREpAGZjTUws0uBccAK4G7gp+5ebmYZwGfAz1JbooiIiCTSaIgDhcAod/8ifqW7V5nZiakpS0RERBrTaIi7+6/MbIiZjQQceNPd3w2f+yjVBYqIiEhiyXzF7JfAA0BngrPy+8zs2lQXJiIiIg1Lpjv9+8Bgdy8DMLNbgHeB36SyMBEREWlYMnenLwRy45ZzgM+T2Xn4vfJPzGyemV1dT5vhZjbLzOaY2WvJ7FdERESSOxPfDMwxsxcIrol/C3jDzG4HcPdLE21kZjHgjrB9CcGAMU+4+9y4Nh2AO4Fj3f1LM+u6I29GRESkNUkmxB8Lf6q9muS+hwLz3H0+gJlNAUYCc+PafB+Y6u5fArj7siT3LSIi0uolc3f6A2aWDfQNV33i7uVJ7LsHsChuuQQYVqdNXyDLzF4FCoA/ufuDSexbRESk1UtmsJfhBHenLwQM6GVm49x9WmObJljnCV7/IGAE0Ab4j5m97e6f1qnhfOB8gD322KOxkkVERFqFZLrTfw98290/ATCzvsBkgvBtSAnQK265J7A4QZsV7r4B2GBm04ADgVoh7u4TgYkAxcXFdT8IiIiItErJ3J2eVR3gAOFZclYS200H9jGzorA7fgzwRJ02/wK+YWaZZpZH0N2uAWRERESSkMyZ+Ewzuwd4KFw+A5jZ2EbuXmFmFwPPATHgXnefY2YXhM/f5e4fmdmzwGygCrjb3T/cnjciIiLS2lgwQVkDDcxygIuAIwiuc08D7nT3zakvb1vFxcU+Y8aMdLy0iIhIWpjZTHcvrru+wTPxcKayme5+APCHVBUnIiIiTdfgNXF3rwLeNzPdEi4iIrKLSeaa+O4EI7a9A2yoXunuJ6esKhEREWlUMiF+Q8qrEBERkSZLJsSPd/er4leY2f8CmqxEREQkjZL5nvi3Eqw7rrkLERERkaap90zczC4Efgz0MbPZcU8VAG+lujARERFpWEPd6X8HngFuBuLnAl/v7qtSWpWIiIg0qt4Qd/e1wFpgbDg3eLewfb6Z5VdPHyoiIiLpkcwsZhcD1wNLCYZGhWA2soGpK0tEREQak8zd6ZcD+7r7yhTXIiIiIk2QzN3piwi61UVERGQXksyZ+HzgVTP7N1Az6Ym7ayx1ERGRNEomxL8Mf7LDHxEREdkFNBri7r7NsKtmlkz4i4iISArVe03czN6Ie/xQnaffSVlFIiIikpSGbmxrG/f4gDrPWQpqERERkSZoKMS9nseJlkVERGQna+jadgczO5Ug6DuY2ahwvQHtU16ZiIiINKihEH8NODnu8Ulxz01LWUUiIiKSlIbGTj9nZxYiIiIiTZPMiG0iIiKyC1KIi4iIRJRCXEREJKIaDXEzO83MCsLH15rZVDMbkvrSREREpCHJnIn/0t3Xm9kRwHeAB4AJqS1LREREGpNMiFeG/54ATHD3f6GJUERERNIumRD/ysz+AnwPeNrMcpLcTkRERFIomTD+HvAccKy7rwE6AT9NZVEiIiLSuGSmFN0d+Le7bzaz4cBA4MFUFiUiIiKNS+ZM/FGg0sz2Bu4BioC/p7QqERERaVQyIV7l7hXAKOA2d7+C4Oy8UWZ2rJl9YmbzzOzqBtodbGaVZjY6ubJFREQkmRAvN7OxwNnAU+G6rMY2MrMYcAdwHNAfGGtm/etp978E191FREQkScmE+DnAocBN7r7AzIqAvyWx3VBgnrvPd/ctwBRgZIJ2lxB02S9LsmYREREhiRB397nAlcAHZnYAUOLutySx7x7AorjlknBdDTPrAZwK3JV0xSIiIgIkcXd6eEf6A8BCwIBeZjbO3RubU9wSrPM6y7cBV7l7pVmi5jU1nA+cD7DHHns0VrKIiEirkMxXzH4PfNvdPwEws77AZOCgRrYrAXrFLfcEFtdpUwxMCQO8EDjezCrc/fH4Ru4+EZgIUFxcXPeDgIiISKuUTIhnVQc4gLt/amaN3tgGTAf2Ca+hfwWMAb4f38Ddi6ofm9n9wFN1A1xEREQSSybEZ5rZPcBD4fIZwMzGNnL3CjO7mOCu8xhwr7vPMbMLwud1HVxERGQHmHvDvdPhWOkXAUcQXOeeBtzp7ptTX962iouLfcaMGel4aRERkbQws5nuXlx3fYNn4maWAcx09wOAP6SqOBEREWm6Br9i5u5VwPtmplvCRUREdjHJToAyx8zeATZUr3T3k1NWlYiIiDQqmRC/IeVViIiISJPVG+LhrGXd3P21OuuPJPjKmIiIiKRRQ9fEbwPWJ1i/MXxORERE0qihEO/t7rPrrnT3GUDvlFUkIiIiSWkoxHMbeK5NcxciIiIiTdNQiE83s/PqrjSzH5DEiG0iIiKSWg3dnX458JiZxQ+zWgxkE0wfKiIiImlUb4i7+1LgMDM7GjggXP1vd395p1QmIiIiDWr0e+Lu/grwyk6oRURERJqgwWFXRUREZNelEBcREYkohbiIiEhEKcRFREQiSiEuIiISUQpxERGRiFKIi4iIRJRCXEREJKIU4iIiIhGlEBcREYkohbiIiEhEKcRFREQiSiEuIiISUQpxERGRiFKIi4iIRJRCXEREJKIU4iIiIhGlEBcREYkohbiIiEhEpTTEzexYM/vEzOaZ2dUJnj/DzGaHP2+Z2YGprEdERKQlSVmIm1kMuAM4DugPjDWz/nWaLQCOcveBwI3AxFTVIyIi0tKk8kx8KDDP3ee7+xZgCjAyvoG7v+Xuq8PFt4GeKaxHRESkRUlliPcAFsUtl4Tr6vMD4JlET5jZ+WY2w8xmLF++vBlLFBERia5UhrglWOcJG5odTRDiVyV63t0nunuxuxd36dKlGUsUERGJrswU7rsE6BW33BNYXLeRmQ0E7gaOc/eVKaxHRESkRUnlmfh0YB8zKzKzbGAM8ER8AzPbA5gKnOXun6awFhERkRYnZWfi7l5hZhcDzwEx4F53n2NmF4TP3wX8CugM3GlmABXuXpyqmkRERFoSc094mXqXVVxc7DNmzEh3GSIiIjuNmc1MdJKrEdtEREQiSiEuIiISUQpxERGRiFKIi4iIRJRCXEREJKIU4iIiIhGlEBcREYkohbiIiEhEKcRFREQiSiEuIiISUQpxERGRiFKIi4iIRJRCXEREJKIU4iIiIhGlEBcREYkohbiIiEhEKcRFREQiSiEuIiISUQpxERGRiFKIi4iIRJRCXEREJKIU4iIiIhGlEBcREYkohbiIiEhEKcRFREQiSiEuIiISUQpxERGRiFKIi4iIRJRCXEREJKIU4iIiIhGV0hA3s2PN7BMzm2dmVyd43szs9vD52WY2JJX1iIiItCQpC3EziwF3AMcB/YGxZta/TrPjgH3Cn/OBCamqR0REpKVJ5Zn4UGCeu8939y3AFGBknTYjgQc98DbQwcx2T2FNIiIiLUYqQ7wHsChuuSRc19Q2IiIikkBmCvdtCdb5drTBzM4n6G4HKDWzT3awtniFwIpm3J/UT8d659Bx3jl0nHcOHefAnolWpjLES4Beccs9gcXb0QZ3nwhMbO4CAcxshrsXp2LfUpuO9c6h47xz6DjvHDrODUtld/p0YB8zKzKzbGAM8ESdNk8AZ4d3qR8CrHX3JSmsSUREpMVI2Zm4u1eY2cXAc0AMuNfd55jZBeHzdwFPA8cD84CNwDmpqkdERKSlSWV3Ou7+NEFQx6+7K+6xAxelsoYkpKSbXhLSsd45dJx3Dh3nnUPHuQEW5KiIiIhEjYZdFRERiahWHeKNDQsrO87MepnZK2b2kZnNMbPL0l1TS2ZmMTN7z8yeSnctLZmZdTCzR8zs4/C/7UPTXVNLZGZXhH83PjSzyWaWm+6adjWtNsSTHBZWdlwF8D/uvh9wCHCRjnNKXQZ8lO4iWoE/Ac+6ez/gQHTMm52Z9QAuBYrd/QCCG6THpLeqXU+rDXGSGxZWdpC7L3H3d8PH6wn+2GlUvhQws57ACcDd6a6lJTOzdsCRwD0A7r7F3dektaiWKxNoY2aZQB4JxhFp7VpziGvI153MzHoDg4H/prmUluo24GdAVZrraOn6AMuB+8JLF3ebWdt0F9XSuPtXwK3Al8ASgnFEnk9vVbue1hziSQ35Ks3DzPKBR4HL3X1duutpaczsRGCZu89Mdy2tQCYwBJjg7oOBDYDuqWlmZtaRoHe0COgOtDWzM9Nb1a6nNYd4UkO+yo4zsyyCAJ/k7lPTXU8LdThwspktJLg09E0z+1t6S2qxSoASd6/uUXqEINSleR0DLHD35e5eDkwFDktzTbuc1hziyQwLKzvIzIzg2uFH7v6HdNfTUrn7z929p7v3Jvhv+WV311lLCrj718AiM9s3XDUCmJvGklqqL4FDzCwv/DsyAt1AuI2Ujti2K6tvWNg0l9USHQ6cBXxgZrPCddeEo/mJRNUlwKTwBGA+GjK62bn7f83sEeBdgm+5vIdGb9uGRmwTERGJqNbcnS4iIhJpCnEREZGIUoiLiIhElEJcREQkohTiIiIiEaUQF5FmY2bDNYOayM6jEBcREYkohbhIK2RmZ5rZO2Y2y8z+Es5DXmpmvzezd83sJTPrErYdZGZvm9lsM3ssHNMaM9vbzF40s/fDbfYKd58fN9f2pHC0LRFJAYW4SCtjZvsBpwOHu/sgoBI4A2gLvOvuQ4DXgOvCTR4ErnL3gcAHcesnAXe4+4EEY1ovCdcPBi4H+hPM+HV4it+SSKvVaoddFWnFRgAHAdPDk+Q2wDKCKUz/Ebb5GzDVzNoDHdz9tXD9A8A/zawA6OHujwG4exlAuL933L0kXJ4F9AbeSPm7EmmFFOIirY8BD7j7z2utNPtlnXYNjcncUBf55rjHlejvjEjKqDtdpPV5CRhtZl0BzKyTme1J8PdgdNjm+8Ab7r4WWG1m3wjXnwW8Fs4JX2Jmp4T7yDGzvJ35JkREn5BFWh13n2tm1wLPm1kGUA5cBGwA9jezmcBaguvmAOOAu8KQjp+x6yzgL2b263Afp+3EtyEiaBYzEQmZWam756e7DhFJnrrTRUREIkpn4iIiIhGlM3EREZGIUoiLiIhElEJcREQkohTiIiIiEaUQFxERiSiFuIiISET9fw6Qr0R4VKLrAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 576x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(acc, label='Training Accuracy')\n",
    "plt.plot(val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([min(plt.ylim()),1])\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('Cross Entropy')\n",
    "plt.ylim([0,1.0])\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fa97ecf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4bbba69e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of layers in the base model:  19\n"
     ]
    }
   ],
   "source": [
    "# Let's take a look to see how many layers are in the base model\n",
    "print(\"Number of layers in the base model: \", len(base_model.layers))\n",
    "\n",
    "# Fine-tune from this layer onwards\n",
    "fine_tune_at = 1\n",
    "\n",
    "# Freeze all the layers before the `fine_tune_at` layer\n",
    "for layer in base_model.layers[:fine_tune_at]:\n",
    "  layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "eb179869",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=False),\n",
    "              optimizer = tf.keras.optimizers.RMSprop(learning_rate=base_learning_rate/10),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "832cf805",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 160, 160, 3)]     0         \n",
      "_________________________________________________________________\n",
      "sequential (Sequential)      (None, 160, 160, 3)       0         \n",
      "_________________________________________________________________\n",
      "tf.__operators__.getitem (Sl (None, 160, 160, 3)       0         \n",
      "_________________________________________________________________\n",
      "tf.math.add (TFOpLambda)     (None, 160, 160, 3)       0         \n",
      "_________________________________________________________________\n",
      "vgg16 (Functional)           (None, 5, 5, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 14,715,201\n",
      "Trainable params: 513\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4f2390e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/25\n",
      "59/59 [==============================] - 52s 814ms/step - loss: 1.2224 - accuracy: 0.5829 - val_loss: 1.0970 - val_accuracy: 0.5751\n",
      "Epoch 11/25\n",
      "59/59 [==============================] - 65s 1s/step - loss: 1.1463 - accuracy: 0.5818 - val_loss: 1.0931 - val_accuracy: 0.5751\n",
      "Epoch 12/25\n",
      "59/59 [==============================] - 68s 1s/step - loss: 1.1140 - accuracy: 0.5904 - val_loss: 1.0891 - val_accuracy: 0.5794\n",
      "Epoch 13/25\n",
      "59/59 [==============================] - 74s 1s/step - loss: 1.1719 - accuracy: 0.5872 - val_loss: 1.0859 - val_accuracy: 0.5837\n",
      "Epoch 14/25\n",
      "36/59 [=================>............] - ETA: 18s - loss: 1.1044 - accuracy: 0.6250"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_22524/2890960901.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mtotal_epochs\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[0minitial_epochs\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mfine_tune_epochs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m history_fine = model.fit(ds_train,\n\u001b[0m\u001b[0;32m      5\u001b[0m                          \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtotal_epochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m                          \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1182\u001b[0m                 _r=1):\n\u001b[0;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1184\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1185\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    883\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    884\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 885\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    886\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    915\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    916\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 917\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    918\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    919\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3037\u001b[0m       (graph_function,\n\u001b[0;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3039\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   3040\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   3041\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1961\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1962\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1963\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1964\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    589\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 591\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "fine_tune_epochs = 15\n",
    "total_epochs =  initial_epochs + fine_tune_epochs\n",
    "\n",
    "history_fine = model.fit(ds_train,\n",
    "                         epochs=total_epochs,\n",
    "                         initial_epoch=history.epoch[-1],\n",
    "                         validation_data=ds_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb744cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc += history_fine.history['accuracy']\n",
    "val_acc += history_fine.history['val_accuracy']\n",
    "\n",
    "loss += history_fine.history['loss']\n",
    "val_loss += history_fine.history['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd07c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(acc, label='Training Accuracy')\n",
    "plt.plot(val_acc, label='Validation Accuracy')\n",
    "plt.ylim([0, 1])\n",
    "plt.plot([initial_epochs-1,initial_epochs-1],\n",
    "          plt.ylim(), label='Start Fine Tuning')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.ylim([0, 1.0])\n",
    "plt.plot([initial_epochs-1,initial_epochs-1],\n",
    "         plt.ylim(), label='Start Fine Tuning')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a648f006",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(ds_val)\n",
    "\n",
    "b =0\n",
    "m = 0\n",
    "for element in predictions :\n",
    "    if(element[0] > 0.5) :\n",
    "        m +=1\n",
    "    elif(element[0]< 0.5) :\n",
    "        b +=1\n",
    "        \n",
    "print(\"Prdictions ;\\n - Malin(s): \", m, \"\\n - Bnins: \", b, \"\\n - Total comp: \", b+m,\" vs \",len(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785ced0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import plot_confusion_matrix  \n",
    "\n",
    "def predict_class_label_number(dataset):\n",
    "    predictions =  model.predict(dataset)\n",
    "    res = np.zeros(len(predictions))\n",
    "    i = 0 \n",
    "    for element in predictions : \n",
    "        if(element[0]> 0.5):\n",
    "            res[i] = 1\n",
    "        i += 1\n",
    "    return tf.convert_to_tensor(res)\n",
    "\n",
    "def give_labels (dataset, size):\n",
    "    lab = np.zeros(size)\n",
    "    i = 0\n",
    "    for batch in dataset:\n",
    "        for element in batch[1] :\n",
    "            lab[i] = element.numpy()\n",
    "            i +=1\n",
    "    return tf.convert_to_tensor(lab)\n",
    "    \n",
    "def show_confusion_matrix(cm, labels):\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.imshow(cm)\n",
    "    plt.colorbar()\n",
    "    plt.xlabel('Prediction')\n",
    "    plt.ylabel('Label')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59fe0431",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dataset = ds_val\n",
    "confusion_mtx = tf.math.confusion_matrix(\n",
    "    give_labels(dataset, size),\n",
    "    predict_class_label_number(dataset),\n",
    "    num_classes=2)\n",
    "show_confusion_matrix(confusion_mtx, [0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148dda0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf631ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81888249",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
