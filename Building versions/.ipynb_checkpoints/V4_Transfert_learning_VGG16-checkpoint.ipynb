{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eae82575",
   "metadata": {},
   "source": [
    "# WIP Data augmentation \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2a75b1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "import PIL.Image\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "import pathlib\n",
    "import pandas as pd\n",
    "\n",
    "import pydicom # for DICOM images\n",
    "from skimage.transform import resize\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "%matplotlib inline\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1022b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed=31415):\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
    "set_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0e7b5f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train has 33,126 rows and Test has 10,982 rows.\n"
     ]
    }
   ],
   "source": [
    "# Directory\n",
    "#directory = '/Users/renau/Desktop/DATA/data_proj_melanoma'\n",
    "directory = '/Users/renau/Desktop/PROJ-H419/data'\n",
    "\n",
    "# Import the 2 csv s\n",
    "train_df = pd.read_csv(directory + '/train.csv')\n",
    "test_df = pd.read_csv(directory + '/test.csv')\n",
    "\n",
    "print('Train has {:,} rows and Test has {:,} rows.'.format(len(train_df), len(test_df)))\n",
    "\n",
    "# Change columns names\n",
    "new_names = ['dcm_name', 'ID', 'sex', 'age', 'anatomy', 'diagnosis', 'benign_malignant', 'target']\n",
    "train_df.columns = new_names\n",
    "test_df.columns = new_names[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e09f3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === JPEG ===\n",
    "# Create the paths\n",
    "path_train = directory + '/jpeg/train/' + train_df['dcm_name'] + '.jpg'\n",
    "path_test = directory + '/jpeg/test/' + test_df['dcm_name'] + '.jpg'\n",
    "\n",
    "# Append to the original dataframes\n",
    "train_df['path_jpeg'] = path_train\n",
    "test_df['path_jpeg'] = path_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "670fb0a1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dcm_name</th>\n",
       "      <th>ID</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>anatomy</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>benign_malignant</th>\n",
       "      <th>target</th>\n",
       "      <th>path_jpeg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>ISIC_0149568</td>\n",
       "      <td>IP_0962375</td>\n",
       "      <td>female</td>\n",
       "      <td>55.0</td>\n",
       "      <td>upper extremity</td>\n",
       "      <td>melanoma</td>\n",
       "      <td>malignant</td>\n",
       "      <td>1</td>\n",
       "      <td>/Users/renau/Desktop/PROJ-H419/data/jpeg/train...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>ISIC_0188432</td>\n",
       "      <td>IP_0135517</td>\n",
       "      <td>female</td>\n",
       "      <td>50.0</td>\n",
       "      <td>upper extremity</td>\n",
       "      <td>melanoma</td>\n",
       "      <td>malignant</td>\n",
       "      <td>1</td>\n",
       "      <td>/Users/renau/Desktop/PROJ-H419/data/jpeg/train...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>ISIC_0207268</td>\n",
       "      <td>IP_7735373</td>\n",
       "      <td>male</td>\n",
       "      <td>55.0</td>\n",
       "      <td>torso</td>\n",
       "      <td>melanoma</td>\n",
       "      <td>malignant</td>\n",
       "      <td>1</td>\n",
       "      <td>/Users/renau/Desktop/PROJ-H419/data/jpeg/train...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>ISIC_0232101</td>\n",
       "      <td>IP_8349964</td>\n",
       "      <td>male</td>\n",
       "      <td>65.0</td>\n",
       "      <td>torso</td>\n",
       "      <td>melanoma</td>\n",
       "      <td>malignant</td>\n",
       "      <td>1</td>\n",
       "      <td>/Users/renau/Desktop/PROJ-H419/data/jpeg/train...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>ISIC_0247330</td>\n",
       "      <td>IP_3232631</td>\n",
       "      <td>female</td>\n",
       "      <td>65.0</td>\n",
       "      <td>lower extremity</td>\n",
       "      <td>melanoma</td>\n",
       "      <td>malignant</td>\n",
       "      <td>1</td>\n",
       "      <td>/Users/renau/Desktop/PROJ-H419/data/jpeg/train...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         dcm_name          ID     sex   age          anatomy diagnosis  \\\n",
       "91   ISIC_0149568  IP_0962375  female  55.0  upper extremity  melanoma   \n",
       "235  ISIC_0188432  IP_0135517  female  50.0  upper extremity  melanoma   \n",
       "314  ISIC_0207268  IP_7735373    male  55.0            torso  melanoma   \n",
       "399  ISIC_0232101  IP_8349964    male  65.0            torso  melanoma   \n",
       "459  ISIC_0247330  IP_3232631  female  65.0  lower extremity  melanoma   \n",
       "\n",
       "    benign_malignant  target  \\\n",
       "91         malignant       1   \n",
       "235        malignant       1   \n",
       "314        malignant       1   \n",
       "399        malignant       1   \n",
       "459        malignant       1   \n",
       "\n",
       "                                             path_jpeg  \n",
       "91   /Users/renau/Desktop/PROJ-H419/data/jpeg/train...  \n",
       "235  /Users/renau/Desktop/PROJ-H419/data/jpeg/train...  \n",
       "314  /Users/renau/Desktop/PROJ-H419/data/jpeg/train...  \n",
       "399  /Users/renau/Desktop/PROJ-H419/data/jpeg/train...  \n",
       "459  /Users/renau/Desktop/PROJ-H419/data/jpeg/train...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "malignant_df = train_df[train_df['target'] == 1]\n",
    "malignant_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d5691d32",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dcm_name</th>\n",
       "      <th>ID</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>anatomy</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>benign_malignant</th>\n",
       "      <th>target</th>\n",
       "      <th>path_jpeg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ISIC_2637011</td>\n",
       "      <td>IP_7279968</td>\n",
       "      <td>male</td>\n",
       "      <td>45.0</td>\n",
       "      <td>head/neck</td>\n",
       "      <td>unknown</td>\n",
       "      <td>benign</td>\n",
       "      <td>0</td>\n",
       "      <td>/Users/renau/Desktop/PROJ-H419/data/jpeg/train...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ISIC_0015719</td>\n",
       "      <td>IP_3075186</td>\n",
       "      <td>female</td>\n",
       "      <td>45.0</td>\n",
       "      <td>upper extremity</td>\n",
       "      <td>unknown</td>\n",
       "      <td>benign</td>\n",
       "      <td>0</td>\n",
       "      <td>/Users/renau/Desktop/PROJ-H419/data/jpeg/train...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ISIC_0052212</td>\n",
       "      <td>IP_2842074</td>\n",
       "      <td>female</td>\n",
       "      <td>50.0</td>\n",
       "      <td>lower extremity</td>\n",
       "      <td>nevus</td>\n",
       "      <td>benign</td>\n",
       "      <td>0</td>\n",
       "      <td>/Users/renau/Desktop/PROJ-H419/data/jpeg/train...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ISIC_0068279</td>\n",
       "      <td>IP_6890425</td>\n",
       "      <td>female</td>\n",
       "      <td>45.0</td>\n",
       "      <td>head/neck</td>\n",
       "      <td>unknown</td>\n",
       "      <td>benign</td>\n",
       "      <td>0</td>\n",
       "      <td>/Users/renau/Desktop/PROJ-H419/data/jpeg/train...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ISIC_0074268</td>\n",
       "      <td>IP_8723313</td>\n",
       "      <td>female</td>\n",
       "      <td>55.0</td>\n",
       "      <td>upper extremity</td>\n",
       "      <td>unknown</td>\n",
       "      <td>benign</td>\n",
       "      <td>0</td>\n",
       "      <td>/Users/renau/Desktop/PROJ-H419/data/jpeg/train...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       dcm_name          ID     sex   age          anatomy diagnosis  \\\n",
       "0  ISIC_2637011  IP_7279968    male  45.0        head/neck   unknown   \n",
       "1  ISIC_0015719  IP_3075186  female  45.0  upper extremity   unknown   \n",
       "2  ISIC_0052212  IP_2842074  female  50.0  lower extremity     nevus   \n",
       "3  ISIC_0068279  IP_6890425  female  45.0        head/neck   unknown   \n",
       "4  ISIC_0074268  IP_8723313  female  55.0  upper extremity   unknown   \n",
       "\n",
       "  benign_malignant  target                                          path_jpeg  \n",
       "0           benign       0  /Users/renau/Desktop/PROJ-H419/data/jpeg/train...  \n",
       "1           benign       0  /Users/renau/Desktop/PROJ-H419/data/jpeg/train...  \n",
       "2           benign       0  /Users/renau/Desktop/PROJ-H419/data/jpeg/train...  \n",
       "3           benign       0  /Users/renau/Desktop/PROJ-H419/data/jpeg/train...  \n",
       "4           benign       0  /Users/renau/Desktop/PROJ-H419/data/jpeg/train...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benin_df = train_df[train_df['target'] == 0]\n",
    "benin_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe8c4729",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "584"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mal_file = malignant_df['path_jpeg'].values\n",
    "mal_labels = malignant_df['target'].values\n",
    "mal_train_ds = tf.data.Dataset.from_tensor_slices((mal_file, mal_labels))\n",
    "len(list(mal_train_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae0eff34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32542"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ben_file = benin_df['path_jpeg'].values\n",
    "ben_labels = benin_df['target'].values\n",
    "ben_train_ds = tf.data.Dataset.from_tensor_slices((ben_file, ben_labels))\n",
    "len(list(ben_train_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d15a23f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32542"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ben_train_ds = ben_train_ds.shuffle(len(list(ben_train_ds)))\n",
    "len(list(ben_train_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "77b57288",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "233 935\n"
     ]
    }
   ],
   "source": [
    "def make_balanced_dataset(ds_class1, ds_class2):\n",
    "    half_size = min(len(list(ds_class1)),len(list(ds_class2)))\n",
    "    ds_1 = ds_class1.take(half_size)\n",
    "    ds_2 = ds_class2.take(half_size)\n",
    "    ds_full = ds_1.concatenate(ds_2)\n",
    "    ds_full = ds_full.shuffle(half_size*2, reshuffle_each_iteration=False)\n",
    "    return ds_full.skip((half_size*2)//5),ds_full.take((half_size*2)//5),\n",
    "#print(make_balanced_dataset(ben_train_ds,mal_train_ds))   \n",
    "ds_train, ds_val = make_balanced_dataset(ben_train_ds,mal_train_ds)\n",
    "size = len(list(ds_val))\n",
    "print(size, len(list(ds_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7452be65",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'/Users/renau/Desktop/PROJ-H419/data/jpeg/train/ISIC_6257422.jpg' and target:  0\n",
      "b'/Users/renau/Desktop/PROJ-H419/data/jpeg/train/ISIC_0599605.jpg' and target:  1\n",
      "b'/Users/renau/Desktop/PROJ-H419/data/jpeg/train/ISIC_0272026.jpg' and target:  0\n",
      "b'/Users/renau/Desktop/PROJ-H419/data/jpeg/train/ISIC_2937642.jpg' and target:  1\n"
     ]
    }
   ],
   "source": [
    "ex_ds = ds_train.take(4)\n",
    "for element in ex_ds :\n",
    "    print(element[0].numpy(),'and target: ',element[1].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "724bf6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image(path, label):\n",
    "    image = tf.io.read_file(path)\n",
    "    image = tf.image.decode_image(image, channels=3, dtype = tf.uint8, expand_animations = False)\n",
    "    return image, label\n",
    "\n",
    "ds_train = ds_train.map(read_image)\n",
    "ds_val = ds_val.map(read_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ae09d9ef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640, 3)\n",
      "(2448, 3264, 3)\n",
      "(4000, 6000, 3)\n"
     ]
    }
   ],
   "source": [
    "ex_ds = ds_train.take(3)\n",
    "for element in ex_ds :\n",
    "    print(element[0].numpy().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "222d1391-24e9-436b-9c34-cd8474bcd4e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 224, 224, 3)\n",
      "(16,)\n",
      "(16, 224, 224, 3)\n",
      "(16,)\n",
      "(16, 224, 224, 3)\n",
      "(16,)\n"
     ]
    }
   ],
   "source": [
    "def adapt_data(image, label):\n",
    "    image = tf.image.resize(image, [160,160])\n",
    "    return image, label\n",
    "\n",
    "def convert_to_float(image, label):\n",
    "    image = tf.image.convert_image_dtype(image, dtype=tf.float64)\n",
    "    return image, label\n",
    "    \n",
    "ds_train= ds_train.map(adapt_data).map(convert_to_float).batch(16)\n",
    "ds_val= ds_val.map(adapt_data).map(convert_to_float).batch(16)\n",
    "\n",
    "ex_ds = ds_train.take(3)\n",
    "for element in ex_ds :\n",
    "    print(element[0].shape)\n",
    "    print(element[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c16f2e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "ds_train = ds_train.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "ds_val = ds_val.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cd9828ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_input = tf.keras.applications.vgg16.preprocess_input\n",
    "IMG_SIZE = (160,160)\n",
    "IMG_SHAPE = IMG_SIZE + (3,)\n",
    "base_model = tf.keras.applications.vgg16.VGG16(\n",
    "    include_top=False,\n",
    "    weights='imagenet',\n",
    "    input_tensor=None,\n",
    "    input_shape=IMG_SHAPE,\n",
    "    pooling=None,\n",
    "    classes=2,\n",
    "    classifier_activation='softmax'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d0281b20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 7, 7, 512)\n"
     ]
    }
   ],
   "source": [
    "image_batch, label_batch = next(iter(ds_train))\n",
    "feature_batch = base_model(image_batch)\n",
    "print(feature_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3c94f445",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, None, None, 3)]   0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, None, None, 64)    1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, None, None, 64)    36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, None, None, 64)    0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, None, None, 128)   73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, None, None, 128)   147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, None, None, 128)   0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, None, None, 256)   295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, None, None, 256)   0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, None, None, 512)   1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 0\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model.trainable = False\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "15fbe6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    preprocessing.RandomContrast(factor=0.1),\n",
    "    preprocessing.RandomFlip(mode='horizontal'), \n",
    "    preprocessing.RandomFlip(mode='vertical'), \n",
    "    preprocessing.RandomRotation(factor=0.20),  \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c64c014d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 512)\n"
     ]
    }
   ],
   "source": [
    "global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
    "feature_batch_average = global_average_layer(feature_batch)\n",
    "print(feature_batch_average.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a4c9f42c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 1)\n"
     ]
    }
   ],
   "source": [
    "prediction_layer = tf.keras.layers.Dense(1, activation = 'sigmoid')\n",
    "prediction_batch = prediction_layer(feature_batch_average)\n",
    "print(prediction_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7cef0199",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape=(160,160, 3))\n",
    "x = data_augmentation(inputs)\n",
    "x = preprocess_input(x)\n",
    "x = base_model(x, training=False)\n",
    "x = global_average_layer(x)\n",
    "x = tf.keras.layers.Dropout(0.2)(x)\n",
    "outputs = prediction_layer(x)\n",
    "model = tf.keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "12cba54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_learning_rate = 0.0001\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=base_learning_rate),\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=False),\n",
    "              metrics=['accuracy', 'binary_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "923df9b0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "sequential (Sequential)      (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "tf.__operators__.getitem (Sl (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "tf.math.add (TFOpLambda)     (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "vgg16 (Functional)           (None, None, None, 512)   14714688  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 14,715,201\n",
      "Trainable params: 513\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d10a0c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b69e86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "59/59 [==============================] - 45s 754ms/step - loss: 1.7504 - accuracy: 0.5016 - binary_accuracy: 0.5016 - val_loss: 1.7604 - val_accuracy: 0.4678 - val_binary_accuracy: 0.4678\n",
      "Epoch 2/10\n",
      "59/59 [==============================] - 140s 2s/step - loss: 1.4637 - accuracy: 0.4727 - binary_accuracy: 0.4727 - val_loss: 1.4776 - val_accuracy: 0.5064 - val_binary_accuracy: 0.5064\n",
      "Epoch 3/10\n",
      "11/59 [====>.........................] - ETA: 39s - loss: 1.2002 - accuracy: 0.5284 - binary_accuracy: 0.5284"
     ]
    }
   ],
   "source": [
    "history = model.fit(ds_train,\n",
    "                    epochs=initial_epochs,\n",
    "                    validation_data=ds_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3818766c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(acc, label='Training Accuracy')\n",
    "plt.plot(val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([min(plt.ylim()),1])\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('Cross Entropy')\n",
    "plt.ylim([0,1.0])\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa97ecf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bbba69e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's take a look to see how many layers are in the base model\n",
    "print(\"Number of layers in the base model: \", len(base_model.layers))\n",
    "\n",
    "# Fine-tune from this layer onwards\n",
    "fine_tune_at = 100\n",
    "\n",
    "# Freeze all the layers before the `fine_tune_at` layer\n",
    "for layer in base_model.layers[:fine_tune_at]:\n",
    "  layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb179869",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=False),\n",
    "              optimizer = tf.keras.optimizers.RMSprop(learning_rate=base_learning_rate/10),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832cf805",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2390e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_tune_epochs = 15\n",
    "total_epochs =  initial_epochs + fine_tune_epochs\n",
    "\n",
    "history_fine = model.fit(ds_train,\n",
    "                         epochs=total_epochs,\n",
    "                         initial_epoch=history.epoch[-1],\n",
    "                         validation_data=ds_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb744cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc += history_fine.history['accuracy']\n",
    "val_acc += history_fine.history['val_accuracy']\n",
    "\n",
    "loss += history_fine.history['loss']\n",
    "val_loss += history_fine.history['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd07c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(acc, label='Training Accuracy')\n",
    "plt.plot(val_acc, label='Validation Accuracy')\n",
    "plt.ylim([0, 1])\n",
    "plt.plot([initial_epochs-1,initial_epochs-1],\n",
    "          plt.ylim(), label='Start Fine Tuning')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.ylim([0, 1.0])\n",
    "plt.plot([initial_epochs-1,initial_epochs-1],\n",
    "         plt.ylim(), label='Start Fine Tuning')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a648f006",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(ds_val)\n",
    "\n",
    "b =0\n",
    "m = 0\n",
    "for element in predictions :\n",
    "    if(element[0] > 0.5) :\n",
    "        m +=1\n",
    "    elif(element[0]< 0.5) :\n",
    "        b +=1\n",
    "        \n",
    "print(\"Prédictions ;\\n - Malin(s): \", m, \"\\n - Bénins: \", b, \"\\n - Total comp: \", b+m,\" vs \",len(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785ced0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import plot_confusion_matrix  \n",
    "\n",
    "def predict_class_label_number(dataset):\n",
    "    predictions =  model.predict(dataset)\n",
    "    res = np.zeros(len(predictions))\n",
    "    i = 0 \n",
    "    for element in predictions : \n",
    "        if(element[0]> 0.5):\n",
    "            res[i] = 1\n",
    "        i += 1\n",
    "    return tf.convert_to_tensor(res)\n",
    "\n",
    "def give_labels (dataset, size):\n",
    "    lab = np.zeros(size)\n",
    "    i = 0\n",
    "    for batch in dataset:\n",
    "        for element in batch[1] :\n",
    "            lab[i] = element.numpy()\n",
    "            i +=1\n",
    "    return tf.convert_to_tensor(lab)\n",
    "    \n",
    "def show_confusion_matrix(cm, labels):\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.imshow(cm)\n",
    "    plt.colorbar()\n",
    "    plt.xlabel('Prediction')\n",
    "    plt.ylabel('Label')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59fe0431",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dataset = ds_val\n",
    "confusion_mtx = tf.math.confusion_matrix(\n",
    "    give_labels(dataset, size),\n",
    "    predict_class_label_number(dataset),\n",
    "    num_classes=2)\n",
    "show_confusion_matrix(confusion_mtx, [0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148dda0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5416ac4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "059e2348",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
